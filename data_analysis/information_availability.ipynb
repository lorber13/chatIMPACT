{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "\n",
    "from tags import * # tags.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = api.list_models(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>...</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>mask_token</th>\n",
       "      <th>card_data</th>\n",
       "      <th>widget_data</th>\n",
       "      <th>model_index</th>\n",
       "      <th>config</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>siblings</th>\n",
       "      <th>spaces</th>\n",
       "      <th>safetensors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DoyyingFace/bert-asian-hate-tweets-self-unclean</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>362e4f4a31d3e877f383139a8d0100acf8cc4f5d</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-02-24 10:25:37+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DoyyingFace/bert-asian-hate-tweets-self-unlean...</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>46b5ea18f5435a8b30697adc78294635ca23558e</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-02-24 15:48:05+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DoyyingFace/bert-cola-finetuned</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>bf99da87b705f17ecab36f87f94b0f708083eafd</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-01-22 03:26:38+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DoyyingFace/bert-tweets-semeval-clean</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>0864a7c8cbbd6f8e3360890a6efea9a3705609d9</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-02-24 14:44:21+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DoyyingFace/bert-tweets-semeval-unclean</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>9576c583a95ff05a923ee1e6d944902160424d60</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-02-24 14:35:55+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DoyyingFace/bert-wiki-comments-finetuned</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>1a297ae6489682c5eded951744afbeb57fe904f8</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-01-23 17:26:54+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DoyyingFace/doyying_bert_first</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>384b3d645858bd1802205f781e845bf478bdcf6f</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-01-17 05:06:52+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DoyyingFace/doyying_bert_first_again</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>5f42382238f1effe8147794d85383c2ec63107df</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-01-17 09:00:22+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>text-classification</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DoyyingFace/dummy-model</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>a271ab21a33b067458d068de1bda9a4bda265369</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-01-17 05:44:26+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DoyyingFace/test-dummy-model</td>\n",
       "      <td>DoyyingFace</td>\n",
       "      <td>83dd7108e7f4726dd5f24817db21d93eb51b3be1</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>2022-01-17 05:54:01+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'rfilename': '.gitattributes', 'size': None,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id       author  \\\n",
       "0    DoyyingFace/bert-asian-hate-tweets-self-unclean  DoyyingFace   \n",
       "1  DoyyingFace/bert-asian-hate-tweets-self-unlean...  DoyyingFace   \n",
       "2                    DoyyingFace/bert-cola-finetuned  DoyyingFace   \n",
       "3              DoyyingFace/bert-tweets-semeval-clean  DoyyingFace   \n",
       "4            DoyyingFace/bert-tweets-semeval-unclean  DoyyingFace   \n",
       "5           DoyyingFace/bert-wiki-comments-finetuned  DoyyingFace   \n",
       "6                     DoyyingFace/doyying_bert_first  DoyyingFace   \n",
       "7               DoyyingFace/doyying_bert_first_again  DoyyingFace   \n",
       "8                            DoyyingFace/dummy-model  DoyyingFace   \n",
       "9                       DoyyingFace/test-dummy-model  DoyyingFace   \n",
       "\n",
       "                                        sha                created_at  \\\n",
       "0  362e4f4a31d3e877f383139a8d0100acf8cc4f5d 2022-03-02 23:29:04+00:00   \n",
       "1  46b5ea18f5435a8b30697adc78294635ca23558e 2022-03-02 23:29:04+00:00   \n",
       "2  bf99da87b705f17ecab36f87f94b0f708083eafd 2022-03-02 23:29:04+00:00   \n",
       "3  0864a7c8cbbd6f8e3360890a6efea9a3705609d9 2022-03-02 23:29:04+00:00   \n",
       "4  9576c583a95ff05a923ee1e6d944902160424d60 2022-03-02 23:29:04+00:00   \n",
       "5  1a297ae6489682c5eded951744afbeb57fe904f8 2022-03-02 23:29:04+00:00   \n",
       "6  384b3d645858bd1802205f781e845bf478bdcf6f 2022-03-02 23:29:04+00:00   \n",
       "7  5f42382238f1effe8147794d85383c2ec63107df 2022-03-02 23:29:04+00:00   \n",
       "8  a271ab21a33b067458d068de1bda9a4bda265369 2022-03-02 23:29:04+00:00   \n",
       "9  83dd7108e7f4726dd5f24817db21d93eb51b3be1 2022-03-02 23:29:04+00:00   \n",
       "\n",
       "              last_modified  private  gated disabled  downloads  likes  ...  \\\n",
       "0 2022-02-24 10:25:37+00:00    False  False     None          5      0  ...   \n",
       "1 2022-02-24 15:48:05+00:00    False  False     None          7      0  ...   \n",
       "2 2022-01-22 03:26:38+00:00    False  False     None          7      0  ...   \n",
       "3 2022-02-24 14:44:21+00:00    False  False     None          4      0  ...   \n",
       "4 2022-02-24 14:35:55+00:00    False  False     None          5      0  ...   \n",
       "5 2022-01-23 17:26:54+00:00    False  False     None          5      0  ...   \n",
       "6 2022-01-17 05:06:52+00:00    False  False     None          0      0  ...   \n",
       "7 2022-01-17 09:00:22+00:00    False  False     None          7      0  ...   \n",
       "8 2022-01-17 05:44:26+00:00    False  False     None          3      0  ...   \n",
       "9 2022-01-17 05:54:01+00:00    False  False     None          0      0  ...   \n",
       "\n",
       "          pipeline_tag mask_token card_data widget_data model_index config  \\\n",
       "0  text-classification       None      None        None        None   None   \n",
       "1  text-classification       None      None        None        None   None   \n",
       "2  text-classification       None      None        None        None   None   \n",
       "3  text-classification       None      None        None        None   None   \n",
       "4  text-classification       None      None        None        None   None   \n",
       "5  text-classification       None      None        None        None   None   \n",
       "6                 None       None      None        None        None   None   \n",
       "7  text-classification       None      None        None        None   None   \n",
       "8            fill-mask       None      None        None        None   None   \n",
       "9                 None       None      None        None        None   None   \n",
       "\n",
       "  transformers_info                                           siblings spaces  \\\n",
       "0              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "1              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "2              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "3              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "4              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "5              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "6              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "7              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "8              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "9              None  [{'rfilename': '.gitattributes', 'size': None,...   None   \n",
       "\n",
       "  safetensors  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "5        None  \n",
       "6        None  \n",
       "7        None  \n",
       "8        None  \n",
       "9        None  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = itertools.islice(models, 0, 1000)\n",
    "models_df = pd.DataFrame(model)\n",
    "models_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'author', 'sha', 'created_at', 'last_modified', 'private',\n",
      "       'gated', 'disabled', 'downloads', 'likes', 'library_name', 'tags',\n",
      "       'pipeline_tag', 'mask_token', 'card_data', 'widget_data', 'model_index',\n",
      "       'config', 'transformers_info', 'siblings', 'spaces', 'safetensors'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(models_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformers',\n",
       " 'pytorch',\n",
       " 'bert',\n",
       " 'text-classification',\n",
       " 'autotrain_compatible',\n",
       " 'endpoints_compatible',\n",
       " 'region:us']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df.loc[0]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformers',\n",
       " 'safetensors',\n",
       " 'llama',\n",
       " 'text-generation',\n",
       " 'facebook',\n",
       " 'meta',\n",
       " 'pytorch',\n",
       " 'llama-3',\n",
       " 'conversational',\n",
       " 'en',\n",
       " 'de',\n",
       " 'fr',\n",
       " 'it',\n",
       " 'pt',\n",
       " 'hi',\n",
       " 'es',\n",
       " 'th',\n",
       " 'arxiv:2204.05149',\n",
       " 'license:llama3.1',\n",
       " 'autotrain_compatible',\n",
       " 'text-generation-inference',\n",
       " 'endpoints_compatible',\n",
       " 'region:us']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model = api.list_models(model_name='meta-llama/Meta-Llama-3.1-8B-Instruct')\n",
    "example_df = pd.DataFrame(example_model)\n",
    "example_df.loc[0]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'zh', 'fr', 'es', 'ru', 'de', 'ja', 'pt', 'ko', 'ar', 'it', 'vi', 'tr', 'hi', 'id', 'pl', 'nl', 'th', 'bn', 'fa', 'sv', 'cs', 'ro', 'fi', 'ca', 'da', 'ta', 'hu', 'uk', 'ind', 'el', 'te', 'ur', 'bg', 'he', 'ms', 'ml', 'sl', 'mr', 'sk', 'sw', 'et', 'eu', 'kn', 'gu', 'sr', 'no', 'hr', 'lt', 'lv', 'pa', 'is', 'yo', 'am', 'vie', 'af', 'ne', 'az', 'mt', 'gl', 'sq', 'si', 'ga', 'or', 'kk', 'tl', 'ceb', 'tha', 'as', 'cy', 'mk', 'hy', 'ha', 'ka', 'my', 'uz', 'eng', 'ig', 'eo', 'be', 'nb', 'km', 'mn', 'ky', 'la', 'zu', 'min', 'so', 'jav', 'xh', 'nn', 'rw', 'ps', 'jv', 'mya', 'yue', 'tt', 'br', 'bs', 'ckb', 'sa', 'lg', 'lo', 'wo', 'ku', 'ug', 'ilo', 'sd', 'ast', 'tw', 'sun', 'tg', 'ace', 'lb', 'nso', 'gd', 'war', 'fil', 'su', 'tk', 'bug', 'oc', 'fy', 'tgl', 'sn', 'khm', 'bjn', 'gn', 'yi', 'ht', 'mai', 'bo', 'ba', 'ban', 'zlm', 'tn', 'fo', 'dv', 'kab', 'ln', 'bm', 'ny', 'cv', 'ti', 'shn', 'sat', 'mi', 'aa', 'mg', 'lao', 'arz', 'sah', 'ee', 'ia', 'st', 'mar', 'pag', 'qu', 'hsb', 'azb', 'ab', 'vec', 'lij', 'mhr', 'sc', 'hin', 'por', 'mni', 'ak', 'ts', 'als', 'tam', 'om', 'li', 'scn', 'tpi', 'rm', 'crh', 'spa', 'fra', 'fur', 'rn', 'nds', 'mad', 'tet', 'pam', 'luo', 'rus', 'pap', 'ltg', 'lmo', 'kmr', 'szl', 'fon', 'ben', 'ch', 'swh', 'hau', 'sm', 'deu', 'ita', 'ary', 'jpn', 'ks', 'tum', 'io', 'urd', 'mal', 'ss', 'nld', 'cmn', 'myv', 'an', 'os', 'bho', 'gom', 'pcm', 'kan', 'yor', 'guj', 'amh', 'pol', 'wa', 'ron', 'kor', 'pes', 'kg', 'cbk', 'pan', 'dan', 'srp', 'swe', 'haw', 'zsm', 'hun', 'ki', 'tel', 'dz', 'kam', 'lug', 'kin', 'afr', 'kw', 'kbp', 'ory', 'kea', 'udm', 'npi', 'ce', 'xho', 'vo', 'mrj', 'jbo', 'som', 'bcl', 'wuu', 'dyu', 'tur', 'awa', 'pnb', 'ibo', 'fj', 'lit', 'quy', 'nya', 'ukr', 'lus', 'umb', 'zul', 'mdf', 'heb', 'co', 'ie', 'mos', 'zho', 'ces', 'cnh', 'krc', 'pms', 'tdt', 'bem', 'sg', 'sna', 'hrv', 'dsb', 'tyv', 'fin', 'bar', 'to', 'sco', 'nap', 'csb', 'ay', 'wol', 'ell', 'azj', 'zgh', 'nan', 'new', 'kbd', 'hil', 've', 'bxr', 'tgk', 'ang', 'gv', 'bh', 'sot', 'vep', 'kac', 'bul', 'bel', 'tzm', 'gle', 'mzn', 'kir', 'cym', 'rue', 'srn', 'xmf', 'av', 'cat', 'asm', 'hne', 'ara', 'gor', 'hat', 'hak', 'bpy', 'slk', 'vls', 'slv', 'isl', 'glk', 'ksh', 'dik', 'xal', 'glg', 'chr', 'lin', 'taq', 'plt', 'prs', 'diq', 'frr', 'kaa', 'se', 'mkd', 'ff', 'mwl', 'jam', 'mnw', 'mlt', 'lez', 'brx', 'rmy', 'lad', 'hye', 'lua', 'koi', 'nob', 'kat', 'lzh', 'san', 'snd', 'got', 'apc', 'epo', 'ltz', 'mri', 'bi', 'twi', 'ydd', 'lfn', 'gaz', 'lvs', 'orm', 'kaz', 'pbt', 'skr', 'guc', 'kv', 'nv', 'ext', 'cjk', 'mag', 'arb', 'bbc', 'nov', 'msa', 'rup', 'kmb', 'bos', 'quc', 'ayr', 'mak', 'uzn', 'kl', 'gag', 'tsn', 'frp', 'fas', 'gan', 'pcd', 'aeb', 'pdc', 'oci', 'gsw', 'fuv', 'lrc', 'lld', 'tso', 'kek', 'iu', 'khk', 'nus', 'gla', 'zea', 'dty', 'eus', 'ty', 'cdo', 'hif', 'ars', 'knc', 'est', 'acq', 'tok', 'acm', 'arn', 'cak', 'uzb', 'cu', 'kik', 'olo', 'grc', 'stq', 'mam', 'inh', 'bew', 'lat', 'pfl', 'ewe', 'shi', 'swa', 'sqi', 'uig', 'za', 'nno', 'aii', 'nij', 'msb', 'aka', 'cho', 'ady', 'vot', 'mqj', 'nep', 'chy', 'bam', 'tcy', 'lbe', 'bod', 'din', 'kur', 'nia', 'pus', 'ae', 'cgc', 'vro', 'sin', 'bas', 'tig', 'dag', 'mus', 'dtp', 'sgs', 'atj', 'taj', 'mon', 'llg', 'pi', 'nhi', 'mh', 'hus', 'arq', 'cr', 'ksw', 'cbr', 'pih', 'tir', 'ik', 'yid', 'quz', 'bre', 'jiv', 'lav', 'bkx', 'hyw', 'mkn', 'nyu', 'kas', 'myk', 'ven', 'qub', 'pnt', 'smo', 'bef', 'kmu', 'ote', 'mui', 'amu', 'fat', 'hla', 'fuf', 'nas', 'cni', 'chd', 'ton', 'ssw', 'tzo', 'ami', 'agr', 'ho', 'kok', 'maz', 'acu', 'alt', 'jra', 'fuh', 'nqo', 'ori', 'top', 'ame', 'chk', 'nrf', 'ng', 'shp', 'quh', 'sxb', 'kbq', 'bzi', 'ii', 'tca', 'rej', 'djk', 'rug', 'cab', 'mic', 'fao', 'nfa', 'tnn', 'tnp', 'hch', 'kr', 'mcd', 'tuk', 'ino', 'lbk', 'qvm', 'krl', 'sps', 'sag', 'mle', 'mlg', 'pwg', 'zam', 'qvh', 'bis', 'tat', 'snn', 'nor', 'mbb', 'nyn', 'toj', 'sml', 'cop', 'wbp', 'hlt', 'hvn', 'qxn', 'kyq', 'kne', 'kj', 'roo', 'boa', 'sme', 'nsn', 'pmf', 'quf', 'bjr', 'nwi', 'srm', 'csy', 'kmg', 'cbi', 'kde', 'wal', 'snk', 'hnj', 'kms', 'arl', 'yap', 'cha', 'hmn', 'aze', 'pon', 'cbs', 'omw', 'tbz', 'ahk', 'ful', 'hns', 'agt', 'cbu', 'bzd', 'hbo', 'bgs', 'ken', 'ctu', 'qve', 'fry', 'iba', 'gym', 'lex', 'bss', 'meu', 'cbt', 'blz', 'zaw', 'ach', 'qvc', 'dje', 'obo', 'kwd', 'awb', 'dgc', 'nuj', 'enm', 'alp', 'nch', 'msk', 'ngu', 'tod', 'heg', 'not', 'mbt', 'lsi', 'na', 'tlh', 'huu', 'yad', 'wrs', 'teo', 'aia', 'kmk', 'ptu', 'blw', 'myu', 'atd', 'sus', 'smk', 'lhu', 'bba', 'ada', 'att', 'kri', 'yva', 'bkd', 'nhe', 'agn', 'bps', 'cof', 'msm', 'auc', 'qvn', 'anp', 'rmc', 'atb', 'gyr', 'mbs', 'doi', 'ded', 'xog', 'trv', 'cmo', 'ixl', 'bpr', 'ese', 'smn', 'rop', 'bon', 'mgh', 'yka', 'mps', 'kpx', 'amp', 'usp', 'dhg', 'kak', 'yao', 'cub', 'bcc', 'kqc', 'poh', 'cao', 'zai', 'snc', 'mxb', 'bbj', 'gwi', 'bgc', 'nst', 'qvw', 'liv', 'mgm', 'ata', 'acr', 'yaa', 'nys', 'hmo', 'ikk', 'yaq', 'laj', 'crx', 'cuk', 'nhw', 'tzj', 'yle', 'zyp', 'udu', 'gul', 'nod', 'opm', 'ncj', 'und', 'tcz', 'mau', 'gun', 'bzj', 'mph', 'suz', 'aoj', 'nuy', 'dgz', 'hub', 'aaz', 'clu', 'fij', 'myw', 'amk', 'poi', 'kje', 'bhg', 'brv', 'ksd', 'tuc', 'run', 'tbl', 'pis', 'ake', 'kwi', 'qvs', 'pib', 'mpm', 'qwh', 'kos', 'qul', 'hbs', 'dzo', 'bdd', 'apu', 'piu', 'mwf', 'sey', 'myx', 'nhg', 'aoi', 'car', 'prf', 'dob', 'lgg', 'yml', 'hui', 'mcf', 'srq', 'azz', 'nbl', 'bmu', 'csw', 'bqc', 'sgb', 'knv', 'vmw', 'abx', 'gum', 'seh', 'amr', 'acf', 'cot', 'bvr', 'gaa', 'mhx', 'abt', 'gcr', 'mto', 'con', 'zap', 'pls', 'gvc', 'ruf', 'ddg', 'kbh', 'ura', 'alq', 'tay', 'gur', 'kkc', 'gup', 'ktm', 'cta', 'zao', 'nak', 'cut', 'ncu', 'gub', 'rro', 'mpx', 'poy', 'kpr', 'mbc', 'wmt', 'zad', 'msy', 'pce', 'spm', 'ubu', 'cav', 'kgp', 'bxh', 'kpw', 'gaw', 'kwj', 'row', 'nrm', 'ign', 'sid', 'lcm', 'yss', 'ksr', 'tgp', 'for', 'zac', 'niu', 'med', 'nbq', 'dwr', 'fai', 'sab', 'kyz', 'kup', 'ong', 'kqf', 'faa', 'gdn', 'kjh', 'wsk', 'wim', 'trc', 'nii', 'caa', 'mwe', 'mmx', 'dnw', 'mcq', 'gux', 'chq', 'lwl', 'okv', 'nxa', 'miq', 'mxt', 'tpu', 'azg', 'nna', 'pwn', 'kwf', 'kjs', 'tke', 'anv', 'rwo', 'bbb', 'sny', 'pau', 'abs', 'kdl', 'bch', 'gdr', 'snl', 'kpg', 'xav', 'dad', 'hto', 'gnn', 'pma', 'qxh', 'rif', 'yet', 'tna', 'wmw', 'auy', 'krr', 'zia', 'loz', 'tbo', 'klv', 'dga', 'iws', 'ghs', 'ikw', 'tnk', 'ood', 'avk', 'aly', 'zpu', 'poe', 'pao', 'fro', 'mkz', 'kew', 'cac', 'mwc', 'geb', 'too', 'soq', 'aui', 'mco', 'mva', 'maa', 'ppo', 'cya', 'amf', 'txu', 'sim', 'mvn', 'xla', 'mwp', 'rgu', 'esk', 'yon', 'khz', 'zaj', 'avt', 'kbc', 'tos', 'mti', 'amm', 'apr', 'xtd', 'ewo', 'bsp', 'zpq', 'wnc', 'kgk', 'tbc', 'ffm', 'kvg', 'yuj', 'enq', 'bbr', 'sue', 'kha', 'lif', 'mdy', 'xtm', 'tcs', 'dmg', 'tmd', 'brb', 'hot', 'crs', 'snp', 'myy', 'gfk', 'guw', 'big', 'mdr', 'emp', 'xbi', 'xmm', 'kpj', 'aau', 'bya', 'apz', 'agu', 'viv', 'adz', 'orv', 'cwe', 'aey', 'kjb', 'sea', 'beu', 'sbe', 'mpj', 'arp', 'kdc', 'tvk', 'zpm', 'ots', 'ape', 'gai', 'gui', 'caf', 'zav', 'djr', 'sgd', 'aso', 'nlg', 'tfr', 'wms', 'gng', 'ebk', 'wuv', 'sja', 'wat', 'mek', 'nin', 'tte', 'tnc', 'swp', 'apb', 'ziw', 'xon', 'tif', 'bhl', 'bla', 'ian', 'mbh', 'plu', 'tuf', 'kmh', 'kcg', 'kyc', 'tgo', 'bnp', 'cpu', 'gvn', 'bsn', 'lac', 'leu', 'khb', 'kaq', 'ttc', 'cap', 'npl', 'tkd', 'ssx', 'buk', 'wbi', 'wed', 'oji', 'jac', 'bus', 'tku', 'tbg', 'zos', 'lgl', 'cfm', 'yua', 'aom', 'tlf', 'mjc', 'pad', 'aln', 'gvf', 'dgr', 'nhr', 'cjv', 'dww', 'mca', 'wap', 'bjp', 'mie', 'etr', 'yal', 'crn', 'bal', 'usa', 'tue', 'kbm', 'tiy', 'dop', 'cax', 'kqw', 'ntp', 'upv', 'ubr', 'mfe', 'guz', 'kkl', 'spp', 'ntu', 'agd', 'pjt', 'sbk', 'gmv', 'zpo', 'gah', 'ncl', 'aon', 'gug', 'guo', 'agg', 'ksj', 'nif', 'uvl', 'zat', 'ter', 'qvi', 'toc', 'kvn', 'mxp', 'otq', 'cbv', 'mbj', 'tiw', 'yut', 'kue', 'huv', 'nca', 'zpv', 'blk', 'sbs', 'box', 'sll', 'kql', 'lns', 'spl', 'gjn', 'qxo', 'txq', 'hre', 'tuo', 'beo', 'nab', 'ido', 'cpa', 'jid', 'mzz', 'pah', 'tbf', 'yrb', 'eve', 'bjk', 'wln', 'cui', 'kpf', 'mih', 'gil', 'guh', 'kal', 'ssg', 'glv', 'cnt', 'aai', 'wos', 'pri', 'rom', 'nou', 'cnl', 'mgc', 'are', 'ekk', 'cle', 'bco', 'daa', 'mir', 'bjz', 'zar', 'hsn', 'quw', 'emi', 'toi', 'tew', 'mbl', 'cpc', 'ccp', 'tom', 'lww', 'msc', 'cso', 'rkb', 'sua', 'muy', 'bea', 'pdu', 'kmo', 'shj', 'ngp', 'mox', 'tly', 'tnt', 'bax', 'kyg', 'nav', 'mux', 'lid', 'thd', 'cbc', 'tav', 'srd', 'bmr', 'zas', 'tee', 'urt', 'cek', 'pot', 'kto', 'mop', 'qug', 'far', 'inb', 'boj', 'ctp', 'tpa', 'dah', 'hop', 'lbb', 'ntj', 'bgt', 'mkl', 'zpl', 'moh', 'xnn', 'urb', 'bmh', 'eri', 'btx', 'yuw', 'zpz', 'tac', 'roh', 'jao', 'bao', 'bkq', 'cpb', 'uvh', 'zca', 'ptp', 'nho', 'pio', 'cjo', 'wbm', 'mgw', 'gcf', 'fli', 'tah', 'spy', 'tar', 'lim', 'hix', 'uri', 'ina', 'nhy', 'met', 'pir', 'stp', 'mil', 'zza', 'mmo', 'apw', 'eko', 'bvd', 'lue', 'ndj', 'nko', 'klt', 'mxq', 'mit', 'mna', 'cuc', 'mcp', 'jae', 'naf', 'knf', 'gam', 'chf', 'oki', 'tof', 'bak', 'mpt', 'bzh', 'nnq', 'ajz', 'yby', 'xed', 'cco', 'qup', 'aer', 'yre', 'nhu', 'gvs', 'kyf', 'ztq', 'mks', 'agq', 'ycn', 'bmk', 'kqa', 'kpv', 'zaa', 'bjv', 'kze', 'mio', 'vmy', 'iou', 'awx', 'jvn', 'kiw', 'pbb', 'mlh', 'noa', 'nyo', 'byr', 'taw', 'wro', 'jni', 'ota', 'imo', 'khs', 'tsw', 'fub', 'cux', 'nss', 'oss', 'ipi', 'sgz', 'mib', 'zab', 'nop', 'kud', 'rai', 'aby', 'byx', 'zpc', 'ctd', 'gnw', 'amn', 'tsz', 'mig', 'amo', 'wnu', 'maj', 'apn', 'wiu', 'cnr', 'knj', 'jic', 'mcr', 'waj', 'mav', 'gof', 'ssd', 'ann', 'cme', 'pab', 'wrk', 'rmn', 'fue', 'mpp', 'agm', 'nde', 'otm', 'hni', 'aoz', 'syc', 'bkm', 'unr', 'tim', 'gwr', 'rmq', 'fkv', 'yom', 'meq', 'swg', 'div', 'nmw', 'boz', 'jmx', 'ckt', 'cpy', 'tvl', 'thk', 'bri', 'ivv', 'abk', 'sri', 'lun', 'urw', 'kby', 'chv', 'prg', 'grn', 'ase', 'tbj', 'lmp', 'amx', 'vif', 'kon', 'xsi', 'hig', 'ses', 'clo', 'loh', 'nzi', 'soy', 'naq', 'tpt', 'stk', 'miz', 'ktu', 'saq', 'tuv', 'kgf', 'nvm', 'ndo', 'srr', 'nr', 'bhd', 'ojb', 'tuz', 'ybh', 'mqb', 'mlp', 'chz', 'atg', 'duu', 'hna', 'che', 'bag', 'koo', 'dwy', 'bqp', 'qvz', 'ons', 'ybb', 'aak', 'swc', 'vid', 'gbm', 'sms', 'mup', 'wer', 'bfz', 'nhx', 'non', 'sma', 'men', 'mcb', 'bze', 'ppl', 'sdh', 'isn', 'cos', 'maq', 'zty', 'mah', 'chp', 'tpz', 'mfy', 'xsm', 'kiu', 'vol', 'hbb', 'nhn', 'nog', 'swb', 'kqn', 'szy', 'ozm', 'kkh', 'yin', 'thl', 'ivb', 'zdj', 'mee', 'ile', 'suk', 'blt', 'yrk', 'rnl', 'brh', 'max', 'isd', 'yij', 'kbx', 'bec', 'nd', 'bfd', 'idu', 'mfq', 'efi', 'fuc', 'oj', 'bkc', 'mgo', 'isu', 'tob', 'pkb', 'adq', 'orh', 'lia', 'bud', 'frm', 'dua', 'lhm', 'tdx', 'tiv', 'mas', 'mnf', 'mxv', 'tkr', 'kxv', 'mfj', 'the', 'omb', 'zyb', 'wes', 'kij', 'mog', 'pex', 'mfh', 'ngn', 'keo', 'mve', 'dig', 'sas', 'oro', 'cor', 'dak', 'bob', 'xkg', 'otk', 'shk', 'ibb', 'nge', 'pov', 'buo', 'mot', 'yea', 'adh', 'mrw', 'zsr', 'gue', 'plw', 'kca', 'bbk', 'akh', 'dao', 'mlw', 'mrn', 'wbr', 'tnl', 'tdg', 'syw', 'kua', 'hoj', 'lgr', 'arg', 'nco', 'baw', 'akb', 'ain', 'ags', 'nym', 'kvt', 'mne', 'lan', 'tio', 'gmh', 'rel', 'kwu', 'nnd', 'nlv', 'otn', 'enb', 'rar', 'nnb', 'aaa', 'bgf', 'syr', 'bum', 'tsb', 'gou', 'nza', 'tzl', 'dov', 'dyo', 'bxa', 'ike', 'rap', 'crk', 'bfm', 'rcf', 'mzm', 'sxn', 'vai', 'cuv', 'que', 'mww', 'bwx', 'tbk', 'lsm', 'gos', 'ppk', 'wni', 'bin', 'bwt', 'kfm', 'apy', 'nlc', 'tpl', 'gbi', 'mhl', 'rhg', 'ify', 'bts', 'lkt', 'sbd', 'ybi', 'alz', 'bci', 'kbo', 'bra', 'qvo', 'mxu', 'mlk', 'lbr', 'tvs', 'dug', 'hup', 'ktz', 'evn', 'kdj', 'luc', 'tzh', 'xmg', 'ium', 'lki', 'nlx', 'lew', 'ena', 'gia', 'lob', 'csa', 'myb', 'dwu', 'ifu', 'sdk', 'kky', 'sda', 'bru', 'bgn', 'bgr', 'mvp', 'bgg', 'mxx', 'zom', 'tdb', 'pnz', 'kng', 'kwx', 'mwn', 'nyy', 'nce', 'gkp', 'rki', 'abz', 'kdh', 'mej', 'ssn', 'smj', 'pcg', 'aym', 'gqr', 'aeu', 'her', 'xbr', 'rub', 'nyq', 'miy', 'tab', 'cag', 'pui', 'ceg', 'ifk', 'xty', 'knn', 'gpe', 'dip', 'mta', 'gaq', 'ifa', 'gdg', 'kum', 'mwv', 'hrx', 'kyu', 'afb', 'xsr', 'bqi', 'wwa', 'mor', 'guk', 'krj', 'kqs', 'bgz', 'ttj', 'ava', 'nla', 'mbi', 'kdi', 'lzz', 'kqe', 'pbu', 'syl', 'mnb', 'bxk', 'enx', 'src', 'shy', 'bwo', 'byn', 'ddn', 'ljp', 'hnn', 'kln', 'mbd', 'akl', 'mhw', 'vun', 'czt', 'due', 'hac', 'pck', 'nci', 'ngl', 'mjw', 'tgj', 'nba', 'dts', 'hz', 'bhp', 'tby', 'pdt', 'rtm', 'bht', 'akk', 'ijs', 'ahr', 'qxu', 'yas', 'kck', 'sbl', 'mgg', 'mwm', 'dgo', 'mtg', 'iii', 'npy', 'nbe', 'tlb', 'btd', 'hwc', 'chj', 'itv', 'zne', 'bhs', 'shs', 'twu', 'aar', 'kru', 'hms', 'fvr', 'cjs', 'plg', 'hoc', 'bik', 'peg', 'rjs', 'cku', 'mnk', 'zro', 'sei', 'mer', 'nag', 'ryu', 'acn', 'btt', 'mhi', 'kfo', 'guu', 'lot', 'udg', 'muv', 'bfa', 'mmn', 'odk', 'slr', 'rmb', 'tem', 'cri', 'nku', 'xcl', 'njo', 'mzi', 'ykg', 'kwn', 'kxp', 'ajg', 'syb', 'bua', 'mzh', 'thy', 'mqy', 'moc', 'mbf', 'amc', 'lhi', 'cnw', 'dbq', 'ldi', 'muh', 'yli', 'rui', 'yns', 'nbc', 'nsa', 'kbr', 'ahg', 'bom', 'raw', 'mqu', 'aqt', 'ute', 'zin', 'kzf', 'bez', 'cyb', 'cce', 'kxm', 'bdh', 'khw', 'sjn', 'bfj', 'kod', 'klb', 'pem', 'tao', 'kqi', 'bdq', 'sch', 'bsk', 'koh', 'bgj', 'tfn', 'acw', 'ngt', 'tls', 'erk', 'isk', 'hea', 'kff', 'bni', 'asa', 'biy', 'kfs', 'nmn', 'dma', 'ihp', 'trp', 'trf', 'haq', 'sro', 'msn', 'zak', 'sop', 'sby', 'way', 'shb', 'dis', 'dnj', 'kmm', 'alj', 'tts', 'bou', 'njm', 'ksp', 'hag', 'ogc', 'qxs', 'ghl', 'szb', 'pmq', 'rag', 'gej', 'bbw', 'tui', 'bhw', 'coe', 'tli', 'nyb', 'enl', 'sgc', 'kuj', 'skg', 'mul', 'tmf', 'bfw', 'dcr', 'mip', 'chm', 'dib', 'esi', 'sba', 'bzt', 'nmc', 'lub', 'bmv', 'njn', 'gbk', 'nid', 'dar', 'lmn', 'qus', 'xtc', 'ker', 'mif', 'bqt', 'lbm', 'lam', 'aol', 'xkv', 'khg', 'trn', 'ikx', 'kxj', 'nph', 'lti', 'mfi', 'nih', 'wno', 'gqa', 'kun', 'tpn', 'pst', 'tek', 'ssp', 'tsi', 'aim', 'shu', 'uzs', 'tih', 'bji', 'ayo', 'avu', 'bno', 'rmo', 'esu', 'eip', 'kyh', 'wsg', 'ifb', 'buw', 'snw', 'irk', 'hdy', 'bot', 'mtp', 'zpi', 'xmv', 'aro', 'miu', 'adi', 'goh', 'gby', 'pum', 'end', 'mrh', 'kix', 'kus', 'crj', 'lui', 'skt', 'lev', 'djm', 'klr', 'bej', 'heh', 'kks', 'mns', 'hdn', 'mua', 'mix', 'mgu', 'kjd', 'sck', 'kit', 'mjg', 'lag', 'mck', 'yur', 'old', 'tll', 'nnw', 'cay', 'shg', 'mrq', 'see', 'guq', 'wlv', 'mgr', 'urk', 'lut', 'sef', 'frc', 'arr', 'nau', 'qva', 'ale', 'xdy', 'bjg', 'lbj', 'rad', 'ndh', 'kmw', 'leh', 'mvv', 'lea', 'dru', 'bvz', 'nim', 'dyi', 'hay', 'nnp', 'ngj', 'laa', 'spn', 'bdv', 'gyd', 'tvu', 'chb', 'ldn', 'suj', 'sgw', 'yan', 'njz', 'sil', 'gww', 'pqm', 'emk', 'moz', 'kfx', 'tap', 'did', 'maw', 'anu', 'kpz', 'crt', 'nut', 'ebu', 'nyh', 'kjc', 'duo', 'kwv', 'ttv', 'mov', 'ort', 'fit', 'ksc', 'jit', 'nbu', 'pai', 'bva', 'abq', 'wca', 'bkl', 'mfm', 'sux', 'aqz', 'xte', 'rim', 'msi', 'ctz', 'mla', 'nfu', 'yak', 'ekg', 'cnk', 'mmy', 'bbq', 'sdc', 'mzj', 'hra', 'ktb', 'any', 'snf', 'tdj', 'gyn', 'kgr', 'mur', 'wau', 'xsb', 'zun', 'jya', 'cgg', 'suc', 'trq', 'otd', 'iso', 'sgh', 'mwq', 'tdc', 'dng', 'hmr', 'lud', 'rwr', 'tsc', 'wdd', 'cld', 'hoy', 'chu', 'oym', 'qxl', 'mbq', 'srb', 'bku', 'bim', 'xnr', 'waw', 'tqo', 'btm', 'gnd', 'chn', 'thq', 'thf', 'kpo', 'apt', 'tnr', 'cas', 'lai', 'tog', 'izh', 'nyk', 'pne', 'kye', 'bje', 'tlj', 'bpx', 'biu', 'ttq', 'mnx', 'nmz', 'jaa', 'bkw', 'soz', 'mde', 'lme', 'odu', 'trs', 'mrz', 'jup', 'alh', 'lis', 'dws', 'gwd', 'adj', 'ndc', 'zag', 'lmk', 'tvt', 'nmf', 'won', 'ocu', 'lwg', 'unk', 'tsg', 'ikt', 'lnd', 'kfc', 'agw', 'wic', 'yrl', 'haz', 'pny', 'nmm', 'pse', 'one', 'bcj', 'bnj', 'rml', 'zoh', 'mat', 'mim', 'shr', 'dav', 'sac', 'shh', 'urh', 'mjl', 'ksb', 'chw', 'ciw', 'rwk', 'kgo', 'yae', 'zyg', 'atq', 'egl', 'mye', 'unx', 'icr', 'jmc', 'dhv', 'iry', 'ggw', 'cla', 'ntk', 'pak', 'ibg', 'ury', 'nio', 'nit', 'kap', 'rin', 'sbp', 'meo', 'kjp', 'nzm', 'bwd', 'pmy', 'mzp', 'qxq', 'iko', 'zlj', 'mhk', 'arw', 'duc', 'qui', 'jun', 'itd', 'gvo', 'hul', 'vas', 'cra', 'weo', 'kih', 'buh', 'mtf', 'thv', 'apd', 'xwg', 'vkl', 'ydg', 'wls', 'lor', 'nja', 'kdr', 'yey', 'chx', 'cll', 'ida', 'psi', 'kvy', 'nnc', 'umm', 'bft', 'srl', 'tii', 'tsv', 'iby', 'kmt', 'ram', 'xks', 'bhb', 'caz', 'geg', 'uki', 'gde', 'wtm', 'noz', 'iwm', 'kbj', 'eka', 'bvm', 'bnx', 'kvv', 'dni', 'gru', 'lbx', 'agh', 'ckx', 'ayz', 'lma', 'mte', 'igs', 'dsh', 'utr', 'noe', 'izr', 'bmm', 'aao', 'nda', 'fpe', 'kst', 'int', 'ekl', 'bpn', 'lmg', 'pei', 'isi', 'aog', 'anc', 'qwa', 'swl', 'akf', 'akp', 'mgf', 'ora', 'var', 'bdi', 'hgm', 'ank', 'tbt', 'tcc', 'iyx', 'bhf', 'kqy', 'czh', 'nmb', 'pnq', 'ish', 'bli', 'kdz', 'hol', 'bzy', 'mep', 'bzf', 'sau', 'oma', 'tqu', 'tus', 'azd', 'ipo', 'com', 'wob', 'ogb', 'lch', 'tkg', 'duw', 'sse', 'kfa', 'gae', 'liu', 'bxb', 'jru', 'knp', 'bfq', 'xvi', 'djc', 'avn', 'pko', 'bhr', 'win', 'nuk', 'slp', 'gra', 'qux', 'aup', 'tmr', 'ite', 'ppq', 'nyi', 'lva', 'zng', 'pbp', 'tpe', 'lkr', 'bte', 'opa', 'lgu', 'lmu', 'poc', 'tix', 'kef', 'iqw', 'cpx', 'xrw', 'sbr', 'skx', 'apm', 'tye', 'loy', 'niw', 'rau', 'luj', 'wji', 'kvq', 'xmh', 'los', 'bjc', 'tlr', 'sdp', 'yaf', 'tro', 'ncb', 'drg', 'bdb', 'lep', 'ruk', 'bbt', 'eky', 'bcf', 'pht', 'kmz', 'dtb', 'dmw', 'biv', 'sif', 'pbo', 'dva', 'ral', 'twf', 'gvj', 'zpn', 'gax', 'gua', 'fab', 'ncm', 'nnh', 'afo', 'nke', 'bqv', 'arv', 'rnd', 'stf', 'twy', 'mrt', 'fqs', 'kcd', 'ebo', 'tiq', 'yra', 'aoa', 'nbh', 'jgk', 'scs', 'mez', 'soe', 'cae', 'wle', 'sym', 'yis', 'bws', 'tva', 'elk', 'wrm', 'ywq', 'fut', 'brq', 'tik', 'swv', 'ngb', 'sad', 'kfz', 'plr', 'wgi', 'ano', 'itz', 'tji', 'jow', 'kbb', 'huh', 'lae', 'agl', 'pic', 'mmc', 'stj', 'bwm', 'pha', 'jna', 'uhn', 'ged', 'bth', 'kjr', 'szp', 'msj', 'kwa', 'kma', 'smw', 'wli', 'otr', 'txt', 'oku', 'kof', 'bol', 'hid', 'xom', 'khu', 'mtr', 'wmb', 'raj', 'pre', 'aec', 'tdh', 'ndv', 'abr', 'mmh', 'psa', 'guf', 'kqj', 'kcx', 'jum', 'mct', 'zim', 'mzk', 'diu', 'erh', 'tti', 'vem', 'mtk', 'sjo', 'knx', 'zoc', 'vaf', 'rab', 'ngz', 'quv', 'tow', 'irx', 'emb', 'mbm', 'kzq', 'alx', 'coz', 'ghn', 'poo', 'les', 'lok', 'cqd', 'deg', 'rgs', 'nuf', 'nhd', 'bmi', 'alw', 'knk', 'dny', 'pua', 'juk', 'sns', 'gwt', 'aee', 'jax', 'liz', 'pac', 'svs', 'ayg', 'nbb', 'neb', 'gdu', 'slc', 'eto', 'zay', 'afh', 'bwq', 'gvr', 'zhi', 'puu', 'yup', 'bhy', 'hux', 'nlo', 'vmp', 'keb', 'gdx', 'gol', 'jbj', 'tgs', 'prx', 'aiw', 'wry', 'gvp', 'kom', 'pww', 'klw', 'tsj', 'kbl', 'kyo', 'dcc', 'bif', 'tdo', 'mfd', 'ats', 'byp', 'scl', 'bgi', 'mwi', 'tcf', 'lkn', 'nnu', 'dya', 'tmy', 'aif', 'bhq', 'kul', 'onp', 'ktv', 'agb', 'agf', 'jiu', 'cly', 'jaq', 'fmp', 'pll', 'kpk', 'lup', 'tpp', 'tbp', 'ysn', 'nux', 'bey', 'grs', 'dnn', 'ulu', 'bet', 'bio', 'hml', 'wbf', 'sjl', 'dgh', 'zbc', 'tlp', 'ael', 'clk', 'mzb', 'sjr', 'dow', 'mjt', 'tra', 'mrp', 'bnv', 'caq', 'lgq', 'dim', 'gwn', 'kui', 'dij', 'ahl', 'ndu', 'knt', 'gid', 'gnb', 'ega', 'mym', 'hts', 'ekr', 'kfp', 'qun', 'dgi', 'atk', 'mlm', 'pcn', 'mnp', 'mcs', 'vaj', 'tty', 'mki', 'lem', 'ass', 'hed', 'sip', 'uar', 'ner', 'kei', 'dms', 'wom', 'kgb', 'itr', 'say', 'blr', 'vag', 'lna', 'grx', 'doz', 'ksg', 'bda', 'yoy', 'ijn', 'ldm', 'ybe', 'ksf', 'pca', 'bmf', 'jqr', 'mlv', 'sdq', 'akc', 'ekp', 'job', 'moj', 'sru', 'lbn', 'kib', 'gek', 'krh', 'der', 'vah', 'xra', 'bdw', 'kol', 'mgl', 'kkk', 'spo', 'pwm', 'khe', 'wlc', 'iri', 'nms', 'sel', 'ril', 'las', 'nar', 'qya', 'bpu', 'inj', 'mug', 'gju', 'kfy', 'nbp', 'cfa', 'bbi', 'anm', 'acv', 'akw', 'yaz', 'yig', 'iru', 'mxe', 'dee', 'tsu', 'buf', 'sgr', 'bjh', 'jer', 'ilu', 'kni', 'twb', 'yog', 'nfd', 'knd', 'lyn', 'kao', 'bqw', 'sbc', 'bsi', 'duq', 'hnd', 'nps', 'aaw', 'ijj', 'xmz', 'kgj', 'ldl', 'lig', 'kjq', 'esh', 'bfy', 'une', 'plv', 'yah', 'kxc', 'asr', 'crq', 'sso', 'tnm', 'mnl', 'sce', 'tww', 'ncr', 'xnz', 'bbf', 'mkc', 'lvk', 'nat', 'iar', 'ttr', 'tuq', 'kna', 'nga', 'sst', 'thr', 'orx', 'ncx', 'hal', 'mqz', 'wlo', 'nhb', 'mho', 'moi', 'rkm', 'tdf', 'juo', 'mrr', 'tpx', 'dna', 'xmw', 'mey', 'kcr', 'gow', 'mln', 'lou', 'pwa', 'yuf', 'xuu', 'ayn', 'xkb', 'xkl', 'aik', 'bpw', 'kai', 'mae', 'kvb', 'zyj', 'wod', 'saw', 'ksi', 'bkv', 'gni', 'lul', 'org', 'mme', 'ztg', 'keu', 'lmy', 'etu', 'psn', 'xns', 'tcx', 'abo', 'kcl', 'daq', 'lbu', 'adx', 'gar', 'iti', 'tce', 'ati', 'tan', 'plc', 'muo', 'ywa', 'fal', 'xmt', 'akd', 'bee', 'biz', 'sdg', 'idi', 'gvl', 'nuo', 'led', 'ayu', 'jms', 'lsr', 'dai', 'kxz', 'naj', 'kyk', 'cbn', 'akg', 'xri', 'pia', 'kxn', 'cbg', 'ccg', 'pru', 'bvw', 'asy', 'msh', 'mtd', 'ijc', 'sjm', 'syk', 'ppi', 'nhv', 'wut', 'kpe', 'oub', 'pip', 'mlu', 'cul', 'bys', 'sax', 'mbo', 'snv', 'emg', 'pym', 'ilb', 'yam', 'dgg', 'dus', 'ahb', 'aul', 'hae', 'mbx', 'sed', 'bpp', 'yyu', 'lu', 'alu', 'azm', 'cjm', 'mkw', 'cto', 'gno', 'nfl', 'mjs', 'bcr', 'tdy', 'kjg', 'cro', 'tsx', 'uiv', 'ymb', 'lar', 'wsa', 'lum', 'ibd', 'nfr', 'zpx', 'qvj', 'hur', 'cjp', 'btu', 'skv', 'asi', 'rji', 'gcd', 'tma', 'ttw', 'krp', 'sui', 'zpw', 'awi', 'ndy', 'cfd', 'kfk', 'meh', 'dks', 'coc', 'kub', 'dur', 'bhz', 'drs', 'ito', 'iyo', 'thz', 'kfr', 'kxh', 'mnm', 'mtt', 'grh', 'twx', 'kvf', 'tpr', 'ler', 'ndd', 'beq', 'bja', 'lef', 'tex', 'fap', 'kwl', 'jbu', 'giw', 'hia', 'kpq', 'bww', 'mpg', 'kvm', 'naz', 'njb', 'wan', 'ygr', 'ncf', 'tcn', 'phk', 'mhz', 'anx', 'ndm', 'haa', 'res', 'llp', 'bsf', 'lgt', 'bby', 'ksn', 'ert', 'ndx', 'bzz', 'mvo', 'mzq', 'saz', 'sgi', 'pmx', 'ayi', 'cbj', 'czn', 'alk', 'yaw', 'wwo', 'ria', 'mtj', 'smy', 'cbd', 'hit', 'bye', 'pwo', 'ula', 'mke', 'ngs', 'mxn', 'ife', 'ndb', 'ssb', 'soc', 'asc', 'mtu', 'tsr', 'nxg', 'alf', 'bvi', 'jeh', 'agx', 'set', 'whk', 'nyj', 'uya', 'zkr', 'tlx', 'mmp', 'shw', 'rwa', 'ghk', 'dtm', 'hru', 'thm', 'tkl', 'qud', 'ung', 'gbe', 'dmo', 'wbl', 'cvn', 'gwa', 'weh', 'sha', 'sqq', 'ttk', 'fod', 'wdj', 'hvv', 'zaz', 'moe', 'ywn', 'ets', 'mng', 'bwe', 'kys', 'owi', 'mdb', 'ney', 'sie', 'lyg', 'sne', 'cch', 'prk', 'zyn', 'bor', 'huf', 'bnn', 'nil', 'bkr', 'vmk', 'mpe', 'rbb', 'bcq', 'mfn', 'tgd', 'akq', 'lcp', 'kcv', 'ebr', 'nka', 'sbb', 'ala', 'mlq', 'lol', 'avd', 'mef', 'cdj', 'tlq', 'bap', 'nng', 'oka', 'coj', 'lwo', 'nlu', 'ssy', 'vra', 'kxw', 'nri', 'kfq', 'ado', 'bmd', 'bcw', 'adn', 'zmp', 'lky', 'gea', 'tei', 'kia', 'tri', 'xub', 'cdn', 'lih', 'brd', 'cko', 'jul', 'mnz', 'muk', 'lnu', 'kfi', 'mcw', 'yuy', 'chl', 'aio', 'yes', 'abu', 'ckl', 'dry', 'brg', 'eme', 'bfg', 'tbw', 'kdq', 'jen', 'gkn', 'gaj', 'dio', 'duv', 'krs', 'ncg', 'aty', 'had', 'mma', 'csh', 'mjx', 'mev', 'mdm', 'hut', 'moa', 'wib', 'bep', 'khn', 'wsi', 'lht', 'lcc', 'lse', 'mhc', 'tgc', 'sry', 'bun', 'byd', 'zgb', 'kgq', 'lop', 'bmb', 'pbs', 'bzk', 'myh', 'fan', 'mbv', 'nyd', 'glo', 'gcn', 'jeb', 'jei', 'boq', 'cog', 'bcg', 'kem', 'lra', 'goa', 'tdk', 'bqj', 'txy', 'ldb', 'dmr', 'vut', 'kxb', 'mwa', 'giz', 'bil', 'gdl', 'kmy', 'rav', 'lbw', 'krx', 'lga', 'jpa', 'fir', 'mlx', 'mbz', 'mmd', 'aqm', 'baa', 'mtq', 'jmb', 'ble', 'kvr', 'ior', 'bky', 'mfl', 'etn', 'kml', 'lil', 'prm', 'bcp', 'aot', 'bab', 'nxr', 'brp', 'mnv', 'glj', 'kel', 'hum', 'rhp', 'tkp', 'bza', 'eot', 'pbi', 'dri', 'kwo', 'orc', 'lec', 'aap', 'krf', 'kwe', 'mue', 'lap', 'bly', 'fie', 'sti', 'aac', 'wrp', 'adl', 'aca', 'ald', 'lmx', 'mbp', 'wyy', 'mpd', 'abi', 'can', 'aal', 'glw', 'nbn', 'mrl', 'pos', 'hoo', 'diz', 'dih', 'hca', 'enn', 'nkx', 'kuy', 'ndr', 'mfc', 'erg', 'scg', 'gga', 'tsa', 'lee', 'bqs', 'tul', 'xem', 'cia', 'gya', 'anw', 'jml', 'lur', 'mlf', 'mxm', 'nbr', 'zpr', 'mkg', 'bsy', 'bub', 'lek', 'afe', 'hmt', 'sur', 'klu', 'siw', 'doa', 'brr', 'tkq', 'yui', 'uuu', 'tdv', 'arh', 'brf', 'eyo', 'kwb', 'doo', 'ths', 'cbo', 'dge', 'ems', 'uba', 'kci', 'sho', 'fak', 'pbg', 'crc', 'toh', 'ldj', 'cfg', 'mij', 'loe', 'aha', 'sbu', 'wmd', 'kpl', 'vay', 'pfe', 'brl', 'tuy', 'kis', 'pbv', 'vaa', 'jmd', 'suv', 'kbz', 'cdm', 'tmq', 'ica', 'gew', 'mrm', 'psh', 'llc', 'avi', 'klz', 'mrf', 'loa', 'ssk', 'suq', 'mro', 'oks', 'xes', 'umu', 'mgb', 'nzk', 'bst', 'iqu', 'tft', 'lpa', 'khc', 'haj', 'raf', 'bcz', 'lla', 'jaf', 'mfv', 'hoe', 'psw', 'mhy', 'kli', 'bei', 'mmm', 'kay', 'awe', 'dsq', 'swj', 'dox', 'kjl', 'bpv', 'glh', 'kza', 'auu', 'nnj', 'aun', 'svb', 'ngc', 'kzi', 'sor', 'byv', 'bbv', 'sug', 'mfb', 'hlb', 'pnu', 'gut', 'kji', 'wad', 'esg', 'ola', 'yer', 'cns', 'bxq', 'jib', 'mls', 'moy', 'oia', 'bau', 'mvz', 'fla', 'tba', 'udl', 'kzr', 'jnj', 'scp', 'sly', 'cob', 'kpc', 'kny', 'sgp', 'bdu', 'gnm', 'gog', 'she', 'mgk', 'sek', 'rir', 'kvd', 'fuy', 'kfd', 'vmz', 'kee', 'aez', 'plk', 'leq', 'coh', 'suy', 'nal', 'ktn', 'mgv', 'sky', 'swi', 'sgy', 'pil', 'cdr', 'swo', 'teq', 'izz', 'ckh', 'nre', 'shq', 'nkb', 'bvc', 'aks', 'cwt', 'jns', 'hmb', 'doy', 'aqg', 'dgd', 'fay', 'mnj', 'txa', 'bca', 'bgp', 'hav', 'slu', 'tgw', 'awn', 'nez', 'kwy', 'bcy', 'bzx', 'njj', 'oyb', 'pkg', 'ttm', 'oke', 'prc', 'knm', 'sde', 'zkd', 'xta', 'ndz', 'mzw', 'ggu', 'qxr', 'dhm', 'cdh', 'dbm', 'kio', 'msw', 'neq', 'kie', 'bgv', 'kla', 'drd', 'mji', 'maf', 'bdm', 'mgi', 'yuz', 'jmr', 'dun', 'ema', 'sam', 'wof', 'kwk', 'hue', 'mvf', 'jma', 'ndi', 'mse', 'etx', 'vam', 'ppm', 'lbq', 'pga', 'sev', 'tug', 'bhj', 'lsh', 'lle', 'siu', 'mfg', 'kez', 'xer', 'mea', 'age', 'yix', 'bqr', 'bib', 'kno', 'bav', 'zik', 'kzs', 'dax', 'huc', 'pdo', 'flr', 'blq', 'xky', 'iki', 'dir', 'gnk', 'szv', 'nbv', 'pcj', 'nac', 'msl', 'gel', 'hmd', 'khq', 'blb', 'pof', 'zae', 'skb', 'knw', 'cyo', 'tal', 'bsc', 'bde', 'ore', 'zrs', 'gna', 'msg', 'kxf', 'dos', 'myp', 'tvd', 'cmr', 'cdf', 'lml', 'ibl', 'kws', 'eza', 'app', 'png', 'vor', 'mzv', 'kil', 'oni', 'bcs', 'aof', 'kcf', 'bzu', 'pcb', 'mzr', 'sou', 'tyn', 'dta', 'tol', 'txn', 'grd', 'kfe', 'gbr', 'lom', 'bid', 'sbh', 'twm', 'kqo', 'auk', 'cje', 'nbm', 'okr', 'mcu', 'dia', 'bfu', 'jge', 'eja', 'klx', 'tdd', 'blm', 'bwu', 'scu', 'kgy', 'zts', 'ymm', 'fng', 'gmb', 'mza', 'osi', 'lro', 'ybj', 'mtl', 'yba', 'igl', 'jig', 'bta', 'hbn', 'sxw', 'nti', 'lje', 'bzv', 'mmg', 'jub', 'kmq', 'gmm', 'otw', 'tis', 'kdu', 'sob', 'eit', 'bqg', 'tcd', 'nen', 'ogo', 'pid', 'pbn', 'ver', 'kvo', 'jio', 'hoa', 'wci', 'gxx', 'xpe', 'svc', 'sto', 'mfz', 'abn', 'sge', 'bks', 'ato', 'sss', 'nir', 'all', 'mfo', 'pmm', 'bcv', 'ilk', 'bpz', 'log', 'iow', 'kbv', 'zwa', 'muz', 'cvg', 'kmn', 'ask', 'dil', 'epi', 'kdx', 'bwi', 'nkh', 'raa', 'kga', 'kdp', 'vnk', 'vmm', 'ctl', 'tau', 'wbk', 'lic', 'ugo', 'hno', 'hah', 'kex', 'nsu', 'dof', 'onn', 'sao', 'zln', 'sen', 'git', 'myl', 'wnp', 'twp', 'kaj', 'kvu', 'mch', 'zps', 'naw', 'fll', 'gdb', 'nkk', 'mpq', 'ono', 'sir', 'ykm', 'bdl', 'bxg', 'nrg', 'siy', 'nup', 'dem', 'oyd', 'niq', 'djn', 'ilp', 'kvj', 'rao', 'afi', 'mwg', 'mkf', 'ofu', 'pkt', 'rmt', 'kzc', 'mgd', 'cja', 'bzw', 'sng', 'beh', 'mdw', 'pss', 'dhi', 'llu', 'nev', 'yun', 'mmz', 'onj', 'orz', 'pqa', 'hwo', 'xod', 'har', 'kkz', 'emn', 'mdj', 'sku', 'szg', 'mdt', 'sol', 'ntm', 'dot', 'tdn', 'mbu', 'dbb', 'gnu', 'wgb', 'mda', 'tld', 'nwb', 'bsh', 'mhu', 'phl', 'wbj', 'acd', 'kmd', 'bbp', 'fip', 'tds', 'sep', 'gri', 'ige', 'snq', 'ifm', 'ctg', 'vrs', 'yum', 'afu', 'stv', 'aki', 'mcn', 'zaf', 'dme', 'rol', 'nud', 'trd', 'yim', 'jle', 'khj', 'kzm', 'jmi', 'smq', 'yll', 'law', 'blc', 'sya', 'frd', 'rah', 'lkh', 'wlx', 'spu', 'kss', 'asu', 'kps', 'nma', 'axk', 'bns', 'dre', 'aab', 'nxq', 'pmi', 'niy', 'ksm', 'xtn', 'kic', 'dor', 'jdt', 'bux', 'tru', 'gbg', 'tmc', 'hio', 'yki', 'gop', 'bbu', 'nnm', 'ums', 'gpa', 'kge', 'lip', 'fud', 'nto', 'aji', 'kdm', 'kcj', 'soj', 'cdz', 'ich', 'tdl', 'nzy', 'nqg', 'clc', 'xkn', 'jku', 'niz', 'sys', 'khy', 'sbg', 'ayb', 'cua', 'gad', 'gdf', 'kid', 'khl', 'yev', 'gab', 'twe', 'lbo', 'scw', 'kqb', 'mxy', 'kfb', 'bkk', 'wja', 'sos', 'mdh', 'mrg', 'vig', 'crl', 'bex', 'gbz', 'aad', 'nyf', 'sdo', 'bit', 'dbj', 'foi', 'amt', 'sts', 'ade', 'xok', 'anj', 'hkk', 'tpm', 'puo', 'cik', 'sok', 'was', 'has', 'mql', 'kdd', 'diw', 'qxp', 'kog', 'ccj', 'ktp', 'mfa', 'ldk', 'qxa', 'ybl', 'twh', 'gis', 'bwr', 'xsu', 'bjt', 'mpc', 'ess', 'thp', 'wti', 'agc', 'byz', 'gaf', 'nli', 'hve', 'zns', 'sig', 'njh', 'puc', 'crw', 'dby', 'nbi', 'prn', 'cnb', 'ego', 'yay', 'nmh', 'brt', 'liq', 'bhh', 'uta', 'piv', 'taz', 'cod', 'add', 'kle', 'tyr', 'grt', 'vap', 'iai', 'nnz', 'dbn', 'bfh', 'tyz', 'lln', 'wew', 'cli', 'ycl', 'bgd', 'kwg', 'bnm', 'khr', 'asb', 'kmc', 'sjg', 'ukp', 'pku', 'gim', 'mqn', 'aix', 'kdt', 'akr', 'nru', 'pek', 'wmo', 'hei', 'klq', 'koe', 'bfs', 'nmk', 'rog', 'zzj', 'gud', 'rey', 'ztp', 'txo', 'lax', 'aba', 'kht', 'pcc', 'ppt', 'bsq', 'kvw', 'tmn', 'arx', 'scv', 'yot', 'ott', 'bxl', 'cry', 'anf', 'dzg', 'blf', 'skj', 'apj', 'peb', 'ynq', 'bek', 'bcn', 'kph', 'daw', 'elm', 'tes', 'mds', 'zmb', 'klg', 'cin', 'nun', 'pyu', 'bof', 'mwt', 'bwf', 'mpn', 'kkj', 'bgq', 'dwa', 'ted', 'mxj', 'kmi', 'qum', 'ksv', 'bse', 'wme', 'lbf', 'sew', 'tic', 'wow', 'ahs', 'pta', 'nsm', 'cou', 'nkw', 'van', 'pav', 'nlj', 'ngi', 'tpj', 'mqx', 'pay', 'lir', 'dbd', 'dhd', 'cte', 'pow', 'prq', 'dbi', 'pln', 'lrl', 'fuu', 'ggb', 'mxd', 'mhs', 'oru', 'dsn', 'ndp', 'bev', 'tgy', 'mcc', 'tjg', 'gro', 'mpr', 'how', 'wlw', 'blh', 'srz', 'mdd', 'kpm', 'jkp', 'wog', 'dei', 'byo', 'irn', 'slz', 'kot', 'boh', 'abm', 'dnd', 'kls', 'saf', 'gox', 'fun', 'bpa', 'wbb', 'mgp', 'pkh', 'ygw', 'xac', 'nhp', 'afz', 'nzb', 'saj', 'pci', 'skd', 'igb', 'jab', 'sav', 'bov', 'kad', 'glr', 'pug', 'mqg', 'tef', 'zrg', 'nos', 'kfu', 'jat', 'kow', 'nqy', 'lel', 'tnv', 'xuj', 'ukw', 'spt', 'zms', 'agi', 'jmn', 'skq', 'tga', 'shm', 'wss', 'nnl', 'dyg', 'snm', 'cox', 'jdg', 'tla', 'klo', 'otx', 'yuq', 'kqp', 'avl', 'duh', 'kqm', 'mum', 'hmj', 'lmd', 'des', 'buz', 'zuy', 'nki', 'sez', 'mny', 'ibm', 'vmj', 'fuq', 'gau', 'anl', 'kwc', 'okx', 'csk', 'xkk', 'kyv', 'tsp', 'tpq', 'ccl', 'nhz', 'shc', 'ngw', 'kep', 'kfg', 'itl', 'nse', 'liw', 'rat', 'krw', 'amb', 'vmx', 'dhn', 'sjb', 'njs', 'dho', 'bhu', 'stn', 'gbv', 'etc', 'clt', 'soo', 'jad', 'yno', 'cde', 'gec', 'ldo', 'zpp', 'vkn', 'asg', 'xkj', 'ztl', 'crv', 'tkb', 'its', 'knz', 'dub', 'qws', 'toq', 'ctt', 'nsy', 'bkg', 'ahp', 'twr', 'atu', 'zau', 'zmq', 'mku', 'kkf', 'sbn', 'yif', 'gbh', 'nmo', 'rng', 'soa', 'itt', 'jbm', 'kch', 'kty', 'rei', 'tml', 'zeh', 'def', 'dez', 'ztx', 'kcq', 'yiq', 'jwi', 'smh', 'uis', 'gyz', 'ghe', 'pbc', 'tgt', 'bmj', 'cmi', 'pwb', 'cov', 'nao', 'agy', 'jda', 'yat', 'wbq', 'zpy', 'cdi', 'yiu', 'vmc', 'cma', 'mkk', 'ors', 'tqb', 'tny', 'njx', 'ate', 'jog', 'yde', 'hrm', 'soi', 'bjx', 'bfb', 'aoe', 'gmz', 'kmj', 'bac', 'bpe', 'kvx', 'byj', 'kuh', 'gry', 'kfv', 'phq', 'kwt', 'cib', 'nmi', 'kjo', 'ldg', 'zkn', 'nqt', 'nlk', 'prt', 'pgg', 'bqh', 'zpk', 'pcl', 'okh', 'xwe', 'gso', 'bbo', 'ojs', 'kra', 'lal', 'usi', 'lpo', 'tng', 'kfh', 'zpg', 'swr', 'rdb', 'cna', 'lhp', 'srx', 'aaf', 'mut', 'kqk', 'vmh', 'nkf', 'nwm', 'sct', 'lhl', 'xtl', 'dkx', 'mdu', 'bqa', 'nyw', 'auq', 'cih', 'aug', 'sfw', 'lrk', 'mtb', 'tks', 'grj', 'yiz', 'gbl', 'nct', 'kyy', 'mel', 'kyb', 'ttb', 'tkt', 'xti', 'goj', 'acz', 'ktc', 'zph', 'ktf', 'grv', 'mrd', 'luz', 'pom', 'tcp', 'sdr', 'kpb', 'kxx', 'sre', 'mjv', 'fad', 'bip', 'krn', 'kki', 'tfi', 'nxk', 'irr', 'zpt', 'ruy', 'xkz', 'nes', 'ntr', 'pbl', 'klk', 'bvy', 'swk', 'pez', 'mxs', 'ssi', 'mnu', 'zpd', 'ont', 'nuz', 'url', 'aww', 'ity', 'eze', 'djo', 'hmg', 'kev', 'bsl', 'kvi', 'sle', 'dzl', 'bka', 'jnd', 'zte', 'bfr', 'kjt', 'kcs', 'kce', 'buj', 'tvn', 'ayt', 'bah', 'pxm', 'hmw', 'mdk', 'cgk', 'mml', 'sgj', 'clj', 'bmq', 'tcu', 'bix', 'cwd', 'sbx', 'wud', 'kip', 'gjk', 'ktj', 'zcd', 'kft', 'atp', 'pud', 'xkf', 'bqx', 'deh', 'wba', 'gok', 'jrt', 'mii', 'dbv', 'drt', 'ayp', 'gas', 'mdn', 'yhd', 'mqh', 'kkd', 'seg', 'ykk', 'nix', 'nni', 'nyg', 'env', 'dgx', 'kku', 'jnl', 'xmc', 'tnb', 'ghr', 'hii', 'smf', 'pdn', 'lri', 'blo', 'tov', 'xwl', 'mpu', 'bjj', 'bxs', 'bjo', 'pps', 'xgu', 'bzs', 'pnc', 'whg', 'xuo', 'kdy', 'awu', 'ckm', 'vav', 'bge', 'olu', 'phr', 'dhw', 'uss', 'cky', 'zpj', 'ksu', 'tou', 'xsn', 'pcf', 'ggg', 'kpa', 'lgm', 'goz', 'btg', 'lik', 'npo', 'mrv', 'gig', 'kzn', 'xtt', 'bfe', 'mhp', 'dka', 'knu', 'smu', 'gbo', 'ost', 'uth', 'smt', 'vum', 'mik', 'tth', 'xtj', 'yeu', 'mxh', 'bqo', 'kmp', 'hld', 'pcw', 'xkt', 'bgw', 'saa', 'skn', 'knl', 'mab', 'kkn', 'pbm', 'kcc', 'bui', 'fwe', 'mxl', 'sfm', 'kif', 'ldp', 'xsq', 'dde', 'byc', 'ymk', 'rme', 'zpe', 'pwr', 'ruz', 'boo', 'ogg', 'dza', 'cnq', 'nxd', 'cnc', 'buu', 'gez', 'akt', 'mxa', 'lmi', 'bga', 'wem', 'pmj', 'tyy', 'nof', 'wkd', 'tkx', 'ldq', 'xrb', 'zpf', 'tto', 'anr', 'ncq', 'mvg', 'tja', 'sjp', 'bhi', 'mzl', 'bha', 'zpa', 'gbn', 'sbz', 'hgw', 'abh', 'gba', 'zbu', 'azt', 'bma', 'nuq', 'tak', 'mjz', 'jiy', 'xdo', 'dln', 'mkb', 'xkc', 'crm', 'sju', 'xum', 'loq', 'hmz', 'pch', 'kej', 'bfo', 'mfk', 'dwz', 'rmz', 'jkr', 'bvu', 'ywl', 'bhx', 'bgx', 'sci', 'das', 'oso', 'key', 'cok', 'lrm', 'aoc', 'slx', 'lie', 'lpn', 'kvl', 'krv', 'piy', 'npb', 'stt', 'sld', 'yax', 'bvh', 'ysp', 'csg', 'zxx', 'mfs', 'prl', 'fse', 'vsl', 'csn', 'aed', 'ymr']\n"
     ]
    }
   ],
   "source": [
    "# Scrape languages from HF\n",
    "\n",
    "url_languages = 'https://huggingface.co/languages'\n",
    "\n",
    "response = requests.get(url_languages)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "code_tags = soup.find_all('code')\n",
    "tag_language = [code_tag.get_text() for code_tag in code_tags]\n",
    "print(tag_language)\n",
    "\n",
    "tag_language.remove('jax') # 'jax' is the ISO for Jambi Malay (present in 3 datasets, 36 models), impossible to distinguish from JAX the library... TODO: better solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(full_name):\n",
    "    pattern = re.compile(r'[^/]+/(.+)')\n",
    "    match = re.search(pattern, full_name)\n",
    "    if match:\n",
    "        return match.group(1) # the part after '/' might also contain version and number of parameters (impossible to extract in a uniform way)\n",
    "    else:\n",
    "        return full_name\n",
    "\n",
    "def match_string(entries, pattern):\n",
    "    pattern = re.compile(pattern)\n",
    "    for entry in entries:\n",
    "        match = pattern.match(entry)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def find_all_matches(entries, pattern):\n",
    "    pattern = re.compile(pattern)\n",
    "    matches = []\n",
    "    for entry in entries:\n",
    "        match = pattern.match(entry)\n",
    "        if match:\n",
    "            matches.append(match.group(1))\n",
    "    return matches\n",
    "\n",
    "def match_license(entries):\n",
    "    return match_string(entries, r'license:(\\S+)')\n",
    "\n",
    "def match_dataset(entries):\n",
    "    return find_all_matches(entries, r'dataset:(\\S+)')\n",
    "\n",
    "def match_uri(entries):\n",
    "    return match_string(entries, r'arxiv:(\\S+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame(api.list_models(model_name='shenzhi-wang/Llama3.1-8B-Chinese-Chat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No emission data available for this model\n"
     ]
    }
   ],
   "source": [
    "# Fill attributes for a random model\n",
    "\n",
    "# TODO: check None attributes\n",
    "\n",
    "model_idx = 0\n",
    "\n",
    "\n",
    "model = models_df.loc[model_idx]\n",
    "model_tags = models_df.loc[model_idx]['tags']\n",
    "try:\n",
    "\tmodel_card_data = next(api.list_models(model_name=model['id'], full=True, cardData=True)).card_data.to_dict()\n",
    "except AttributeError:\n",
    "\tprint('No card data available for this model')\n",
    "model_attributes = dict()\n",
    "\n",
    "model_attributes['name'] = extract_name(model['id'])\n",
    "model_attributes['version'] = None # in model['id'] but impossible to extract in a uniform way\n",
    "model_attributes['number of parameters'] = None # sometimes in model['id'] -> difficult to extract, sometimes in model description on HF\n",
    "\n",
    "model_attributes['quantization'] = None\n",
    "for t in model_tags:\n",
    "\tif t in tag_quantization:\n",
    "\t\tmodel_attributes['quantization'] = t\n",
    "\n",
    "model_attributes['architecture'] = None\n",
    "try:\n",
    "\tmodel_attributes['architecture'] = model_card_data['base_model']\n",
    "except KeyError:\n",
    "\tprint('No architecture data available for this model')\n",
    "\n",
    "model_attributes['language'] = []\n",
    "for t in model_tags:\n",
    "\tif t in tag_language:\n",
    "\t\tmodel_attributes['language'].append(t)\n",
    "\n",
    "model_attributes['model creator'] = None # TODO: if base_model exists, look for 'author' of the base model\n",
    "try: \n",
    "\tbase_model = model_card_data['base_model']\n",
    "\tbase_model_data = pd.DataFrame(api.list_models(model_name=base_model, full=True))\n",
    "\tmodel_attributes['model creator'] = base_model_data.loc[0]['author']\n",
    "except KeyError:\n",
    "\tprint('No base model data available for this model')\n",
    "\n",
    "model_attributes['developer'] = model['author']\n",
    "\n",
    "model_attributes['license to use'] = match_license(model_tags)\n",
    "\n",
    "model_attributes['library'] = [] # TODO: change type into list(str) in our model\n",
    "for t in model_tags:\n",
    "\tif t in tag_library:\n",
    "\t\tmodel_attributes['library'].append(t)\n",
    "\n",
    "model_attributes['context length'] = None\n",
    "model_attributes['open source'] = True\n",
    "\n",
    "model_attributes['uri'] = match_uri(model_tags)\n",
    "\n",
    "model_attributes['fine-tuned'] = None # if there is a 'base_model' in card_data, it is fine-tuned\n",
    "\n",
    "model_attributes['carbon emission'] = None\n",
    "try:\n",
    "\tmodel_attributes['carbon emission'] = model_card_data['co2_eq_emissions']\n",
    "except KeyError:\n",
    "\tprint('No emission data available for this model')\n",
    "\n",
    "model_attributes['tokenizer'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                               shenzhi-wang/Llama3.1-8B-Chinese-Chat\n",
       "author                                                            None\n",
       "sha                                                               None\n",
       "created_at                                   2024-07-24 07:28:39+00:00\n",
       "last_modified                                                     None\n",
       "private                                                          False\n",
       "gated                                                             None\n",
       "disabled                                                          None\n",
       "downloads                                                        29312\n",
       "likes                                                              129\n",
       "library_name                                              transformers\n",
       "tags                 [transformers, safetensors, gguf, llama, text-...\n",
       "pipeline_tag                                           text-generation\n",
       "mask_token                                                        None\n",
       "card_data                                                         None\n",
       "widget_data                                                       None\n",
       "model_index                                                       None\n",
       "config                                                            None\n",
       "transformers_info                                                 None\n",
       "siblings                                                          None\n",
       "spaces                                                            None\n",
       "safetensors                                                       None\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df.loc[model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformers',\n",
       " 'safetensors',\n",
       " 'gguf',\n",
       " 'llama',\n",
       " 'text-generation',\n",
       " 'llama-factory',\n",
       " 'orpo',\n",
       " 'conversational',\n",
       " 'en',\n",
       " 'zh',\n",
       " 'base_model:meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       " 'base_model:quantized:meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       " 'doi:10.57967/hf/2779',\n",
       " 'license:llama3.1',\n",
       " 'autotrain_compatible',\n",
       " 'text-generation-inference',\n",
       " 'endpoints_compatible',\n",
       " 'region:us']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name: Llama3.1-8B-Chinese-Chat\n",
      "  version: None\n",
      "  number of parameters: None\n",
      "  quantization: None\n",
      "  architecture: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "  language: ['en', 'zh']\n",
      "  model creator: meta-llama\n",
      "  developer: None\n",
      "  license to use: llama3.1\n",
      "  library: ['transformers', 'safetensors', 'gguf']\n",
      "  context length: None\n",
      "  open source: True\n",
      "  uri: None\n",
      "  fine-tuned: None\n",
      "  carbon emission: None\n",
      "  tokenizer: None\n"
     ]
    }
   ],
   "source": [
    "for key, value in model_attributes.items():\n",
    "\tprint(f\"{'  '}{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate availability of attributes\n",
    "\n",
    "availability = pd.DataFrame(columns=['id', 'entity name', 'attribute name', 'available API', 'available scraping'])\n",
    "\n",
    "llm_attributes = ['name', 'version', 'number of parameters', 'quantization', 'architecture', 'language', 'model creator', 'license to use', 'library framework', 'context length', 'developer', 'open source', 'uri', 'fine-tuned', 'carbon emission', 'tokenizer']\n",
    "llm_attributes_API_availability = [True, False, False, False, False, True, True, True, True, False, False, False, True, False, True, False]\n",
    "availability['id'] = models_df['id']\n",
    "availability['entity name'] = 'LLM'\n",
    "availability = availability.loc[availability.index.repeat(len(llm_attributes))].reset_index(drop=True)\n",
    "availability['attribute name'] = llm_attributes * len(models_df)\n",
    "availability['available API'] = llm_attributes_API_availability * len(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity name</th>\n",
       "      <th>attribute name</th>\n",
       "      <th>available API</th>\n",
       "      <th>available scraping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>name</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>version</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>number of parameters</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>quantization</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>architecture</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>language</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>model creator</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>license to use</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>library framework</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>context length</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>developer</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>open source</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>uri</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>fine-tuned</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>carbon emission</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>albert/albert-base-v1</td>\n",
       "      <td>LLM</td>\n",
       "      <td>tokenizer</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>name</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>version</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>number of parameters</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>quantization</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>architecture</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>language</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>model creator</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>license to use</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>library framework</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>context length</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>developer</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>open source</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>uri</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>fine-tuned</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>carbon emission</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>albert/albert-base-v2</td>\n",
       "      <td>LLM</td>\n",
       "      <td>tokenizer</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id entity name        attribute name  available API  \\\n",
       "0   albert/albert-base-v1         LLM                  name           True   \n",
       "1   albert/albert-base-v1         LLM               version          False   \n",
       "2   albert/albert-base-v1         LLM  number of parameters          False   \n",
       "3   albert/albert-base-v1         LLM          quantization          False   \n",
       "4   albert/albert-base-v1         LLM          architecture          False   \n",
       "5   albert/albert-base-v1         LLM              language           True   \n",
       "6   albert/albert-base-v1         LLM         model creator           True   \n",
       "7   albert/albert-base-v1         LLM        license to use           True   \n",
       "8   albert/albert-base-v1         LLM     library framework           True   \n",
       "9   albert/albert-base-v1         LLM        context length          False   \n",
       "10  albert/albert-base-v1         LLM             developer          False   \n",
       "11  albert/albert-base-v1         LLM           open source          False   \n",
       "12  albert/albert-base-v1         LLM                   uri           True   \n",
       "13  albert/albert-base-v1         LLM            fine-tuned          False   \n",
       "14  albert/albert-base-v1         LLM       carbon emission           True   \n",
       "15  albert/albert-base-v1         LLM             tokenizer          False   \n",
       "16  albert/albert-base-v2         LLM                  name           True   \n",
       "17  albert/albert-base-v2         LLM               version          False   \n",
       "18  albert/albert-base-v2         LLM  number of parameters          False   \n",
       "19  albert/albert-base-v2         LLM          quantization          False   \n",
       "20  albert/albert-base-v2         LLM          architecture          False   \n",
       "21  albert/albert-base-v2         LLM              language           True   \n",
       "22  albert/albert-base-v2         LLM         model creator           True   \n",
       "23  albert/albert-base-v2         LLM        license to use           True   \n",
       "24  albert/albert-base-v2         LLM     library framework           True   \n",
       "25  albert/albert-base-v2         LLM        context length          False   \n",
       "26  albert/albert-base-v2         LLM             developer          False   \n",
       "27  albert/albert-base-v2         LLM           open source          False   \n",
       "28  albert/albert-base-v2         LLM                   uri           True   \n",
       "29  albert/albert-base-v2         LLM            fine-tuned          False   \n",
       "30  albert/albert-base-v2         LLM       carbon emission           True   \n",
       "31  albert/albert-base-v2         LLM             tokenizer          False   \n",
       "\n",
       "   available scraping  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "5                 NaN  \n",
       "6                 NaN  \n",
       "7                 NaN  \n",
       "8                 NaN  \n",
       "9                 NaN  \n",
       "10                NaN  \n",
       "11                NaN  \n",
       "12                NaN  \n",
       "13                NaN  \n",
       "14                NaN  \n",
       "15                NaN  \n",
       "16                NaN  \n",
       "17                NaN  \n",
       "18                NaN  \n",
       "19                NaN  \n",
       "20                NaN  \n",
       "21                NaN  \n",
       "22                NaN  \n",
       "23                NaN  \n",
       "24                NaN  \n",
       "25                NaN  \n",
       "26                NaN  \n",
       "27                NaN  \n",
       "28                NaN  \n",
       "29                NaN  \n",
       "30                NaN  \n",
       "31                NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "availability.head(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = api.list_datasets(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>paperswithcode_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>siblings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amirveyseh/acronym_identification</td>\n",
       "      <td>amirveyseh</td>\n",
       "      <td>15ef643450d589d5883e289ffadeb03563e80a9e</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2024-01-09 11:39:57+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>19</td>\n",
       "      <td>acronym-identification</td>\n",
       "      <td>[task_categories:token-classification, annotat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ade-benchmark-corpus/ade_corpus_v2</td>\n",
       "      <td>ade-benchmark-corpus</td>\n",
       "      <td>4ba01c71687dd7c996597042449448ea312126cf</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2024-01-09 11:42:58+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>451</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>[task_categories:text-classification, task_cat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCLNLP/adversarial_qa</td>\n",
       "      <td>UCLNLP</td>\n",
       "      <td>c2d5f738db1ad21a4126a144dfbb00cb51e0a4a9</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2023-12-21 14:20:00+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>192</td>\n",
       "      <td>32</td>\n",
       "      <td>adversarialqa</td>\n",
       "      <td>[task_categories:question-answering, task_ids:...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yale-LILY/aeslc</td>\n",
       "      <td>Yale-LILY</td>\n",
       "      <td>2305f2e63b68056f9b9037a3805c8c196e0d5581</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2024-01-09 11:49:13+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "      <td>aeslc</td>\n",
       "      <td>[task_categories:summarization, annotations_cr...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nwu-ctext/afrikaans_ner_corpus</td>\n",
       "      <td>nwu-ctext</td>\n",
       "      <td>445834a997dce8b40e1d108638064381de80c497</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2024-01-09 11:51:47+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>[task_categories:token-classification, task_id...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fancyzhx/ag_news</td>\n",
       "      <td>fancyzhx</td>\n",
       "      <td>eb185aade064a813bc0b7f42de02595523103ca4</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2024-03-07 12:02:37+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6511</td>\n",
       "      <td>122</td>\n",
       "      <td>ag-news</td>\n",
       "      <td>[task_categories:text-classification, task_ids...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allenai/ai2_arc</td>\n",
       "      <td>allenai</td>\n",
       "      <td>210d026faf9955653af8916fad021475a3f00453</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2023-12-21 15:09:48+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>571510</td>\n",
       "      <td>107</td>\n",
       "      <td>None</td>\n",
       "      <td>[task_categories:question-answering, task_ids:...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>google/air_dialogue</td>\n",
       "      <td>google</td>\n",
       "      <td>dbdbe7bcef8d344bc3c68a05600f3d95917d6898</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2024-03-07 15:22:15+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>[task_categories:text-generation, task_categor...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>komari6/ajgt_twitter_ar</td>\n",
       "      <td>komari6</td>\n",
       "      <td>af3f2fa5462ac461b696cb300d66e07ad366057f</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2024-01-09 11:58:01+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>[task_categories:text-classification, task_ids...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>legacy-datasets/allegro_reviews</td>\n",
       "      <td>legacy-datasets</td>\n",
       "      <td>71593d1379934286885c53d147bc863ffe830745</td>\n",
       "      <td>2022-03-02 23:29:22+00:00</td>\n",
       "      <td>2024-01-09 11:59:39+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>allegro-reviews</td>\n",
       "      <td>[task_categories:text-classification, task_ids...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id                author  \\\n",
       "0   amirveyseh/acronym_identification            amirveyseh   \n",
       "1  ade-benchmark-corpus/ade_corpus_v2  ade-benchmark-corpus   \n",
       "2               UCLNLP/adversarial_qa                UCLNLP   \n",
       "3                     Yale-LILY/aeslc             Yale-LILY   \n",
       "4      nwu-ctext/afrikaans_ner_corpus             nwu-ctext   \n",
       "5                    fancyzhx/ag_news              fancyzhx   \n",
       "6                     allenai/ai2_arc               allenai   \n",
       "7                 google/air_dialogue                google   \n",
       "8             komari6/ajgt_twitter_ar               komari6   \n",
       "9     legacy-datasets/allegro_reviews       legacy-datasets   \n",
       "\n",
       "                                        sha                created_at  \\\n",
       "0  15ef643450d589d5883e289ffadeb03563e80a9e 2022-03-02 23:29:22+00:00   \n",
       "1  4ba01c71687dd7c996597042449448ea312126cf 2022-03-02 23:29:22+00:00   \n",
       "2  c2d5f738db1ad21a4126a144dfbb00cb51e0a4a9 2022-03-02 23:29:22+00:00   \n",
       "3  2305f2e63b68056f9b9037a3805c8c196e0d5581 2022-03-02 23:29:22+00:00   \n",
       "4  445834a997dce8b40e1d108638064381de80c497 2022-03-02 23:29:22+00:00   \n",
       "5  eb185aade064a813bc0b7f42de02595523103ca4 2022-03-02 23:29:22+00:00   \n",
       "6  210d026faf9955653af8916fad021475a3f00453 2022-03-02 23:29:22+00:00   \n",
       "7  dbdbe7bcef8d344bc3c68a05600f3d95917d6898 2022-03-02 23:29:22+00:00   \n",
       "8  af3f2fa5462ac461b696cb300d66e07ad366057f 2022-03-02 23:29:22+00:00   \n",
       "9  71593d1379934286885c53d147bc863ffe830745 2022-03-02 23:29:22+00:00   \n",
       "\n",
       "              last_modified  private  gated  disabled  downloads  likes  \\\n",
       "0 2024-01-09 11:39:57+00:00    False  False     False        115     19   \n",
       "1 2024-01-09 11:42:58+00:00    False  False     False        451     25   \n",
       "2 2023-12-21 14:20:00+00:00    False  False     False        192     32   \n",
       "3 2024-01-09 11:49:13+00:00    False  False     False         82     12   \n",
       "4 2024-01-09 11:51:47+00:00    False  False     False         85      6   \n",
       "5 2024-03-07 12:02:37+00:00    False  False     False       6511    122   \n",
       "6 2023-12-21 15:09:48+00:00    False  False     False     571510    107   \n",
       "7 2024-03-07 15:22:15+00:00    False  False     False         44     15   \n",
       "8 2024-01-09 11:58:01+00:00    False  False     False         84      3   \n",
       "9 2024-01-09 11:59:39+00:00    False  False     False         61      4   \n",
       "\n",
       "        paperswithcode_id                                               tags  \\\n",
       "0  acronym-identification  [task_categories:token-classification, annotat...   \n",
       "1                    None  [task_categories:text-classification, task_cat...   \n",
       "2           adversarialqa  [task_categories:question-answering, task_ids:...   \n",
       "3                   aeslc  [task_categories:summarization, annotations_cr...   \n",
       "4                    None  [task_categories:token-classification, task_id...   \n",
       "5                 ag-news  [task_categories:text-classification, task_ids...   \n",
       "6                    None  [task_categories:question-answering, task_ids:...   \n",
       "7                    None  [task_categories:text-generation, task_categor...   \n",
       "8                    None  [task_categories:text-classification, task_ids...   \n",
       "9         allegro-reviews  [task_categories:text-classification, task_ids...   \n",
       "\n",
       "  card_data siblings  \n",
       "0        {}     None  \n",
       "1        {}     None  \n",
       "2        {}     None  \n",
       "3        {}     None  \n",
       "4        {}     None  \n",
       "5        {}     None  \n",
       "6        {}     None  \n",
       "7        {}     None  \n",
       "8        {}     None  \n",
       "9        {}     None  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = list(itertools.islice(datasets, 0, 10))\n",
    "datasets_df = pd.DataFrame(datasets)\n",
    "datasets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'author', 'sha', 'created_at', 'last_modified', 'private',\n",
       "       'gated', 'disabled', 'downloads', 'likes', 'paperswithcode_id', 'tags',\n",
       "       'card_data', 'siblings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                   amirveyseh/acronym_identification\n",
       "author                                                      amirveyseh\n",
       "sha                           15ef643450d589d5883e289ffadeb03563e80a9e\n",
       "created_at                                   2022-03-02 23:29:22+00:00\n",
       "last_modified                                2024-01-09 11:39:57+00:00\n",
       "private                                                          False\n",
       "gated                                                            False\n",
       "disabled                                                         False\n",
       "downloads                                                          115\n",
       "likes                                                               19\n",
       "paperswithcode_id                               acronym-identification\n",
       "tags                 [task_categories:token-classification, annotat...\n",
       "card_data                                                           {}\n",
       "siblings                                                          None\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_categories:question-answering',\n",
       " 'task_ids:extractive-qa',\n",
       " 'task_ids:open-domain-qa',\n",
       " 'annotations_creators:crowdsourced',\n",
       " 'language_creators:found',\n",
       " 'multilinguality:monolingual',\n",
       " 'source_datasets:original',\n",
       " 'language:en',\n",
       " 'license:cc-by-sa-4.0',\n",
       " 'size_categories:10K<n<100K',\n",
       " 'format:parquet',\n",
       " 'modality:text',\n",
       " 'library:datasets',\n",
       " 'library:pandas',\n",
       " 'library:mlcroissant',\n",
       " 'library:polars',\n",
       " 'arxiv:2002.00293',\n",
       " 'arxiv:1606.05250',\n",
       " 'region:us']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df.loc[2]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_language(entries):\n",
    "    return find_all_matches(entries, r'language:(\\S+)')\n",
    "\n",
    "def match_size(entries):\n",
    "    return match_string(entries, r'size_categories:(\\S+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill attributes for a random dataset\n",
    "\n",
    "# TODO: check None attributes\n",
    "\n",
    "dataset_idx = 0\n",
    "\n",
    "dataset = datasets_df.loc[dataset_idx]\n",
    "dataset_tags = datasets_df.loc[dataset_idx]['tags']\n",
    "dataset_attributes = dict()\n",
    "\n",
    "dataset_attributes['name'] = extract_name(dataset['id'])\n",
    "\n",
    "dataset_attributes['language'] = match_language(dataset_tags)\n",
    "\n",
    "dataset_attributes['dataset creator'] = dataset['author'] # TODO: add attribute in our model?\n",
    "\n",
    "dataset_attributes['license to use'] = match_license(dataset_tags)\n",
    "\n",
    "dataset_attributes['uri'] = match_uri(dataset_tags) # TODO: add multiple URIs when available?\n",
    "\n",
    "dataset_attributes['fine-tuning'] = None\n",
    "\n",
    "dataset_attributes['domain'] = []\n",
    "for t in dataset_tags:\n",
    "\tif t in tag_domain:\n",
    "\t\tdataset_attributes['domain'].append(t)\n",
    "\n",
    "dataset_attributes['size'] = match_size(dataset_tags) # TODO: how to deal with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_categories:token-classification',\n",
       " 'annotations_creators:expert-generated',\n",
       " 'language_creators:found',\n",
       " 'multilinguality:monolingual',\n",
       " 'source_datasets:original',\n",
       " 'language:en',\n",
       " 'license:mit',\n",
       " 'size_categories:10K<n<100K',\n",
       " 'format:parquet',\n",
       " 'modality:text',\n",
       " 'library:datasets',\n",
       " 'library:pandas',\n",
       " 'library:mlcroissant',\n",
       " 'library:polars',\n",
       " 'arxiv:2010.14678',\n",
       " 'region:us',\n",
       " 'acronym-identification']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name: acronym_identification\n",
      "  language: ['en']\n",
      "  dataset creator: amirveyseh\n",
      "  license to use: mit\n",
      "  uri: 2010.14678\n",
      "  fine-tuning: None\n",
      "  domain: []\n",
      "  size: 10K<n<100K\n"
     ]
    }
   ],
   "source": [
    "for key, value in dataset_attributes.items():\n",
    "\tprint(f\"{'  '}{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: text-classification\n",
      "Processed: token-classification\n",
      "Processed: table-question-answering\n",
      "Processed: question-answering\n",
      "Processed: zero-shot-classification\n",
      "Processed: translation\n",
      "Processed: summarization\n",
      "Processed: feature-extraction\n",
      "Processed: text-generation\n",
      "Processed: text2text-generation\n",
      "Processed: fill-mask\n",
      "Processed: sentence-similarity\n",
      "JSON file 'huggingface_tasks.json' has been created.\n"
     ]
    }
   ],
   "source": [
    "# TODO: save converted datasets to JSON in a new directory\n",
    "\n",
    "def fetch_and_extract_text(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        target_paragraph = soup.find('p', class_='text-[1.2rem] text-gray-500')\n",
    "        \n",
    "        if target_paragraph:\n",
    "            return target_paragraph.get_text().strip()\n",
    "        else:\n",
    "            return \"Target paragraph not found.\"\n",
    "    else:\n",
    "        return f\"Failed to fetch the webpage. Status code: {response.status_code}\"\n",
    "\n",
    "def create_tasks_json():\n",
    "    tasks_data = []\n",
    "\n",
    "    for task in TAG_DOWNSTREAM_TASK:\n",
    "        url = f\"https://huggingface.co/tasks/{task}\"\n",
    "        description = fetch_and_extract_text(url)\n",
    "        \n",
    "        tasks_data.append({\n",
    "            \"name\": task,\n",
    "            \"description\": description, # TODO: text2text generation has no description\n",
    "            \"sub-task\": []\n",
    "        })\n",
    "        \n",
    "        print(f\"Processed: {task}\")\n",
    "        # time.sleep(0.5)  # Be polite to the server\n",
    "\n",
    "    with open('huggingface_tasks.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(tasks_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"JSON file 'huggingface_tasks.json' has been created.\")\n",
    "\n",
    "\n",
    "create_tasks_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "# Scrape metrics and descriptions from HF\n",
    "\n",
    "url_metrics = 'https://huggingface.co/metrics'\n",
    "\n",
    "response = requests.get(url_metrics)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "h4_tags = soup.find_all('h4')\n",
    "metrics = [h4_tag.get_text(strip=True) for h4_tag in h4_tags]\n",
    "# print(metrics)\n",
    "\n",
    "p_tags = soup.find_all('p')\n",
    "descriptions = [p_tag.get_text() for p_tag in p_tags]\n",
    "descriptions = descriptions[2:] # drop first lines\n",
    "# print(descriptions)\n",
    "\n",
    "# remove from the list the metrics withoud description (not useful for our purpose)\n",
    "metrics.remove('AlhitawiMohammed22/CER_Hu-Evaluation-Metrics')\n",
    "metrics.remove('Aye10032/loss_metric')\n",
    "metrics.remove('giulio98/code_eval_outputs')\n",
    "metrics.remove('maysonma/lingo_judge_metric')\n",
    "metrics.remove('lvwerra/test')\n",
    "metrics.remove('sma2023/wil')\n",
    "\n",
    "\n",
    "assert len(metrics) == len(descriptions)\n",
    "print(len(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "# from the lists, remove the descriptions and then the relative metric in the same index that have in the description 'TODO: add a description here\\n\\t\\t\\t\\t\\t\\t'ArithmeticError\n",
    "\n",
    "for i, description in enumerate(descriptions):\n",
    "    if 'TODO: add a description here' in description:\n",
    "        metrics.pop(i)\n",
    "        descriptions.pop(i)\n",
    "\n",
    "assert len(metrics) == len(descriptions)\n",
    "print(len(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'Babelscape/rebel-large', 'dataset': 'Babelscape/rebel-dataset'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_idx = 96\n",
    "\n",
    "model = models_df.loc[model_idx]\n",
    "model_tags = models_df.loc[model_idx]['tags']\n",
    "\n",
    "datasets = match_dataset(model_tags)\n",
    "#datasets = [extract_name(dataset) for dataset in datasets]\n",
    "\n",
    "train_relationship = dict()\n",
    "for dataset in datasets:\n",
    "    train_relationship = {\n",
    "        \"model_id\": model['id'],\n",
    "        \"dataset_id\": dataset,\n",
    "    }\n",
    "\n",
    "train_relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suited for relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'Ayham/bert_gpt2_summarization_xsum',\n",
       " 'task': 'text2text-generation'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_idx = 12\n",
    "\n",
    "model = models_df.loc[model_idx]\n",
    "model_tags = models_df.loc[model_idx]['tags']\n",
    "suited_for_relationship = dict()\n",
    "\n",
    "for t in model_tags:\n",
    "\tif t in TAG_DOWNSTREAM_TASK:\n",
    "\t\tsuited_for_relationship = {\n",
    "        \"model_id\": model['id'],\n",
    "        \"task\": t,\n",
    "    }\n",
    "\n",
    "suited_for_relationship"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
