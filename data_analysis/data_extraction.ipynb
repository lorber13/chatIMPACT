{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from huggingface_hub.utils import logging\n",
    "\n",
    "from tags import * # tags.py\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape languages from HF\n",
    "\n",
    "url_languages = 'https://huggingface.co/languages'\n",
    "\n",
    "default_path = \"/home/csavelli/database/HF entries/hf extracted json/\"\n",
    "\n",
    "response = requests.get(url_languages)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "code_tags = soup.find_all('code')\n",
    "tag_language = [code_tag.get_text() for code_tag in code_tags]\n",
    "\n",
    "tag_language.remove('jax') # 'jax' is the ISO for Jambi Malay (present in 3 datasets, 36 models), impossible to distinguish from JAX the library... TODO: better solution?\n",
    "\n",
    "tag_language = set(tag_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern matching functions\n",
    "\n",
    "def extract_name(full_name):\n",
    "    pattern = re.compile(r'[^/]+/(.+)')\n",
    "    match = re.search(pattern, full_name)\n",
    "    if match:\n",
    "        return match.group(1) # the part after '/' might also contain version and number of parameters (impossible to extract in a uniform way)\n",
    "    else:\n",
    "        return full_name\n",
    "\n",
    "def match_string(entries, pattern):\n",
    "    pattern = re.compile(pattern)\n",
    "    for entry in entries:\n",
    "        match = pattern.match(entry)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def find_all_matches(entries, pattern):\n",
    "    pattern = re.compile(pattern)\n",
    "    matches = []\n",
    "    for entry in entries:\n",
    "        match = pattern.match(entry)\n",
    "        if match:\n",
    "            matches.append(match.group(1))\n",
    "    return matches\n",
    "\n",
    "def match_license(entries):\n",
    "    return match_string(entries, r'license:(\\S+)')\n",
    "\n",
    "def match_dataset(entries):\n",
    "    return find_all_matches(entries, r'dataset:(\\S+)')\n",
    "\n",
    "def match_uri(entries):\n",
    "    uri = match_string(entries, r'arxiv:(\\S+)')\n",
    "    if uri is None:\n",
    "        uri = match_string(entries, r'doi:(\\S+)')\n",
    "    return uri\n",
    "\n",
    "def match_language(entries):\n",
    "    return find_all_matches(entries, r'language:(\\S+)')\n",
    "\n",
    "def match_size(entries):\n",
    "    return match_string(entries, r'size_categories:(\\S+)')\n",
    "\n",
    "def match_tasks(entries):\n",
    "    return find_all_matches(entries, r'task_categories:(\\S+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_json_file(data, file_path):\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r+', encoding='utf-8') as f:\n",
    "\n",
    "            f.seek(0, os.SEEK_END)\n",
    "            f.seek(f.tell() - 1, os.SEEK_SET)\n",
    "            f.truncate()\n",
    "            f.write(',\\n')\n",
    "            json.dump(data, f, indent=4)\n",
    "            f.write(']')\n",
    "    else:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump([data], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "parent_path = os.path.dirname(current_path)\n",
    "result_path = os.path.join(parent_path, 'database', 'HF entries', 'hf extracted json')\n",
    "os.makedirs(result_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all models\n",
    "\n",
    "# models = api.list_models(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the first 1000 models\n",
    "\n",
    "# model = itertools.islice(models, 0, 1000)\n",
    "# models_df = pd.DataFrame(model)\n",
    "# models_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_attributes(model):\n",
    "\n",
    "\tmodel_tags = model.tags\n",
    "\tif model.card_data is not None:\n",
    "\t\tmodel_card_data = model.card_data.to_dict()\n",
    "\telse:\n",
    "\t\tmodel_card_data = None\n",
    "\tmodel_attributes = dict()\n",
    "\n",
    "\tmodel_attributes['name'] = extract_name(model.id)\n",
    "\tmodel_attributes['id'] = model.id\n",
    "\tmodel_attributes['version'] = None # sometimes in model['id'] but impossible to extract in a uniform way\n",
    "\tmodel_attributes['numberOfParameters'] = None # sometimes in model['id'] or model description but impossible to extract in a uniform way\n",
    "\n",
    "\tmodel_attributes['quantization'] = None\n",
    "\tfor t in model_tags:\n",
    "\t\tif t in tag_quantization:\n",
    "\t\t\tmodel_attributes['quantization'] = t\n",
    "\n",
    "\tmodel_attributes['architecture'] = None\n",
    "\ttry:\n",
    "\t\tif model_card_data is not None:\n",
    "\t\t\tmodel_attributes['architecture'] = model_card_data['base_model']\n",
    "\texcept KeyError:\n",
    "\t\tpass\n",
    "\n",
    "\tmodel_attributes['languages'] = []\n",
    "\tfor t in model_tags:\n",
    "\t\tif t in tag_language:\n",
    "\t\t\tmodel_attributes['languages'].append(t)\n",
    "\n",
    "\tmodel_attributes['modelCreator'] = None # extracted in a postprocessing step\n",
    "\n",
    "\tmodel_attributes['licenseToUse'] = match_license(model_tags)\n",
    "\n",
    "\tmodel_attributes['libraryFramework'] = [] \n",
    "\tfor t in model_tags:\n",
    "\t\tif t in tag_library:\n",
    "\t\t\tmodel_attributes['libraryFramework'].append(t)\n",
    "\n",
    "\tmodel_attributes['contextLength'] = None\n",
    "\tmodel_attributes['developers'] = [model.author]\n",
    "\tmodel_attributes['openSource'] = True\n",
    "\n",
    "\tmodel_attributes['uri'] = match_uri(model_tags)\n",
    "\n",
    "\tmodel_attributes['fineTuned'] = None # if there is a 'base_model' in card_data, it is fine-tuned\n",
    "\ttry:\n",
    "\t\tif model_card_data is not None:\n",
    "\t\t\tif 'base_model' in model_card_data:\n",
    "\t\t\t\tmodel_attributes['fineTuned'] = True\n",
    "\texcept KeyError:\n",
    "\t\tpass\n",
    "\n",
    "\tmodel_attributes['carbonEmission [CO2eq tons]'] = None\n",
    "\ttry:\n",
    "\t\tif model_card_data is not None:\n",
    "\t\t\tmodel_attributes['carbonEmission [CO2eq tons]'] = model_card_data['co2_eq_emissions']\n",
    "\texcept KeyError:\n",
    "\t\tpass\n",
    "\n",
    "\tmodel_attributes['tokenizer'] = None\n",
    "\tmodel_attributes['likes'] = model.likes\n",
    "\n",
    "\tinfo = api.model_info(repo_id=model.id, expand=\"downloadsAllTime\")\n",
    "\tmodel_attributes['downloads_all_time'] = info.downloads_all_time\n",
    "\n",
    "\tmodel_attributes['downloads'] = model.downloads\n",
    "\n",
    "\tmodel_attributes['creation_date'] = model.created_at.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\t# Convert both datetimes to timezone-naive\n",
    "\tstarting_datetime = pd.to_datetime(model.created_at).tz_localize(None)\n",
    "\tcurrent_datetime = pd.to_datetime('today').tz_localize(None)\n",
    "\n",
    "\t# evaluate how many years have passed since the creation \n",
    "\tmodel_attributes[\"age\"] = (current_datetime - starting_datetime).days / 365\n",
    "\n",
    "\n",
    "\treturn model_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(result_path, 'models_duplicates_no_modelCreator.json')\n",
    "\n",
    "# Total: 697,162 models\n",
    "count = 0\n",
    "start_time = time.time()\n",
    "for task in TAG_DOWNSTREAM_TASK:\n",
    "    print(f'Processing {task} models...')\n",
    "    models = api.list_models(filter=task, full=True, cardData=True)\n",
    "    for model in models:\n",
    "        model_attributes = extract_model_attributes(model)\n",
    "        add_to_json_file(model_attributes, file_path)\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(f'{count} models processed, {time.time() - start_time} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in TAG_DOWNSTREAM_TASK:\n",
    "    print(f'Processing {task} models...')\n",
    "    models = api.list_models(filter=task, full=True, cardData=True)\n",
    "    for model in models:\n",
    "        model_attributes = extract_model_attributes(model)\n",
    "        add_to_json_file(model_attributes, \"text\")\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(f'{count} models processed, {time.time() - start_time} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data as a DataFrame\n",
    "with open(default_path + \"models_duplicates_no_modelCreator.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "models_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "print(f'len before removing duplicates: {  len(models_df) }')\n",
    "models_df = models_df.loc[models_df.astype(str).drop_duplicates().index]\n",
    "print(f'len after removing duplicates: {  len(models_df) }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocessing: find the modelCreator\n",
    "\n",
    "df_filtered = models_df[models_df['architecture'].notna()]\n",
    "\n",
    "# Process each row\n",
    "count = 0\n",
    "start_time = time.time()\n",
    "for index, row in df_filtered.iterrows():\n",
    "    # Find the row where 'id' matches the 'architecture' of the current row\n",
    "    try:\n",
    "        matching_row = models_df[models_df['id'].astype(str) == str(row['architecture'])]\n",
    "    except ValueError:\n",
    "        break\n",
    "    \n",
    "    if not matching_row.empty:\n",
    "        # Get the first developer from the 'developers' list\n",
    "        first_developer = matching_row['developers'].iloc[0][0] if matching_row['developers'].iloc[0] else None\n",
    "        # Set the 'modelCreator' attribute of the original row\n",
    "        models_df.at[index, 'modelCreator'] = first_developer\n",
    "    \n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(f'{count} rows processed ({count/len(df_filtered)*100} %), elapsed time: {time.time() - start_time} seconds, estimated time remaining: {(time.time() - start_time) / count * (len(df_filtered) - count)} seconds')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = models_df.drop(columns=['id']).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_postprocessed = os.path.join(result_path, 'models.json')\n",
    "\n",
    "with open(file_path_postprocessed, \"w\") as json_file:\n",
    "    json.dump(models_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all datasets\n",
    "\n",
    "# datasets = api.list_datasets(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the first 1000 models\n",
    "\n",
    "# datasets = list(itertools.islice(datasets, 0, 1000))\n",
    "# datasets_df = pd.DataFrame(datasets)\n",
    "# datasets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file_size_to_gb(file_size_str):\n",
    "    \"\"\"\n",
    "    Convert the file size string (e.g., '74.6 kB') to gigabytes (GB).\n",
    "    \"\"\"\n",
    "    file_size_parts = file_size_str.split()\n",
    "    file_size = float(file_size_parts[0])\n",
    "    unit = file_size_parts[1]\n",
    "\n",
    "    conversion_factors = {\n",
    "        'B': 1 / (1024 ** 3),\n",
    "        'kB': 1 / (1024 ** 2),\n",
    "        'MB': 1 / 1024,\n",
    "        'GB': 1,\n",
    "        'TB': 1024,\n",
    "    }\n",
    "\n",
    "    if unit in conversion_factors:\n",
    "        return float(file_size * conversion_factors[unit])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_file_size(url):\n",
    "    # Fetch the HTML content from the provided URL\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the div containing the \"Size of downloaded dataset files:\" text\n",
    "    size_label_div = soup.find('div', string='Size of downloaded dataset files:')\n",
    "\n",
    "    if size_label_div:\n",
    "        # Find the next sibling div containing the file size\n",
    "        size_div = size_label_div.find_next('div')\n",
    "        if size_div:\n",
    "            # Extract the file size text\n",
    "            file_size = size_div.get_text(strip=True)\n",
    "            return file_size\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datasets_attributes(dataset):\n",
    "\n",
    "\tdataset_tags = dataset.tags\n",
    "\tdataset_attributes = dict()\n",
    "\n",
    "\tdataset_attributes['name'] = extract_name(dataset.id)\n",
    "\tdataset_attributes['size [GB]'] = match_size(dataset_tags)\n",
    "\n",
    "\t# url = \"https://huggingface.co/datasets/\" + dataset.id\n",
    "\t# file_size_str = extract_file_size(url)\n",
    "\t# if file_size_str:\n",
    "\t# \tfile_size_gb = convert_file_size_to_gb(file_size_str)\n",
    "\t# \tif file_size_gb:\n",
    "\t# \t\tdataset_attributes['size [GB]'] = file_size_gb\n",
    "\n",
    "\tdataset_attributes['languages'] = match_language(dataset_tags)\n",
    "\n",
    "\t# dataset_attributes['dataset creator'] = dataset['author'] # TODO: add attribute in our model?\n",
    "\n",
    "\tdataset_attributes['licenseToUse'] = match_license(dataset_tags)\n",
    "\n",
    "\tdataset_attributes['domain'] = []\n",
    "\tfor t in dataset_tags:\n",
    "\t\tif t in tag_domain:\n",
    "\t\t\tdataset_attributes['domain'].append(t)\n",
    "\n",
    "\tdataset_attributes['uri'] = match_uri(dataset_tags)\n",
    "\n",
    "\tdataset_attributes['fineTuning'] = None\n",
    "\n",
    "\treturn dataset_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(result_path, 'datasets_duplicates_new.json')\n",
    "\n",
    "count = 0\n",
    "start_time = time.time()\n",
    "for task in TAG_DOWNSTREAM_TASK:\n",
    "    print(f'Processing {task} datasets...')\n",
    "    datasets = api.list_datasets(task_categories=task, full=True)\n",
    "    for dataset in datasets:\n",
    "        dataset_attributes = extract_datasets_attributes(dataset)\n",
    "        add_to_json_file(dataset_attributes, file_path)\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(f'{count} datasets processed, {time.time() - start_time} seconds elapsed, estimated time remaining: {(time.time() - start_time) / count:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data as a DataFrame\n",
    "\n",
    "file_path = os.path.join(result_path, 'datasets_duplicates_new.json')\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "datasets_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "print(f'len before removing duplicates: {len(datasets_df)}')\n",
    "datasets_df = datasets_df.loc[datasets_df.astype(str).drop_duplicates().index]\n",
    "print(f'len after removing duplicates: {len(datasets_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_list = datasets_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_postprocessed = os.path.join(result_path, 'datasets.json')\n",
    "\n",
    "with open(file_path_postprocessed, \"w\") as json_file:\n",
    "    json.dump(datasets_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_extract_text(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        target_paragraph = soup.find('p', class_='text-[1.2rem] text-gray-500')\n",
    "        \n",
    "        if target_paragraph:\n",
    "            return target_paragraph.get_text().strip()\n",
    "        else:\n",
    "            return \"Target paragraph not found.\"\n",
    "    else:\n",
    "        return f\"Failed to fetch the webpage. Status code: {response.status_code}\"\n",
    "\n",
    "def create_tasks_json():\n",
    "\n",
    "    current_path = os.getcwd()\n",
    "    parent_path = os.path.dirname(current_path)\n",
    "    result_path = os.path.join(parent_path, 'database', 'hf extracted json')\n",
    "    os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "    tasks_data = []\n",
    "\n",
    "    for task in TAG_DOWNSTREAM_TASK:\n",
    "        url = f\"https://huggingface.co/tasks/{task}\"\n",
    "        description = fetch_and_extract_text(url)\n",
    "        \n",
    "        tasks_data.append({\n",
    "            \"name\": task,\n",
    "            \"description\": description,\n",
    "            \"sub-task\": []\n",
    "        })\n",
    "        \n",
    "        print(f\"Processed: {task}\")\n",
    "        # time.sleep(0.5)  # Be polite to the server\n",
    "    \n",
    "    file_path = os.path.join(result_path, 'downstreamtasks.json')\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(tasks_data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tasks_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape metrics and descriptions from HF\n",
    "\n",
    "def extract_metrics():\n",
    "\tmetrics = api.list_metrics()\n",
    "\n",
    "\tmetrics_names = [metric.id for metric in metrics]\n",
    "\tmetrics_descriptions = [metric.description for metric in metrics]\n",
    "\n",
    "\t# url_metrics = 'https://huggingface.co/metrics'\n",
    "\n",
    "\t# # Remove from the list the metrics withoud description (not useful for our purpose)\n",
    "\t# metrics.remove('AlhitawiMohammed22/CER_Hu-Evaluation-Metrics')\n",
    "\t# metrics.remove('Aye10032/loss_metric')\n",
    "\t# metrics.remove('giulio98/code_eval_outputs')\n",
    "\t# metrics.remove('maysonma/lingo_judge_metric')\n",
    "\t# metrics.remove('lvwerra/test')\n",
    "\t# metrics.remove('sma2023/wil')\n",
    "\n",
    "\t# From the lists, replace the description 'TODO: add a description here' with None\n",
    "\n",
    "\tfor i, description in enumerate(metrics_descriptions):\n",
    "\t\tif type(description) is not str or 'TODO: add a description here' in description:\n",
    "\t\t\tmetrics_descriptions[i] = None\n",
    "\t\n",
    "\treturn metrics_names, metrics_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_json():\n",
    "\n",
    "    metrics_data = []\n",
    "\n",
    "    metrics, descriptions = extract_metrics()\n",
    "    \n",
    "    for idx in range(len(metrics)):\n",
    "        metric_attributes = dict()\n",
    "\n",
    "        metric_attributes['name'] = metrics[idx]\n",
    "        metric_attributes['description'] = descriptions[idx]\n",
    "        metric_attributes['trained'] = None\n",
    "        metric_attributes['context'] = None\n",
    "        metric_attributes['featureBased/endToEnd'] = None\n",
    "        metric_attributes['granularity'] = None\n",
    "\n",
    "        metrics_data.append(metric_attributes)\n",
    "    \n",
    "    file_path = os.path.join(result_path, 'metrics.json')\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metrics_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_metrics_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_relationship():\n",
    "\n",
    "    file_path = os.path.join(result_path, 'train_duplicates.json')\n",
    "\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    for task in TAG_DOWNSTREAM_TASK:\n",
    "        print(f'Processing {task} models...')\n",
    "        models = api.list_models(filter=task, full=True)\n",
    "        for model in models:\n",
    "            model_tags = model.tags\n",
    "            datasets = match_dataset(model_tags)\n",
    "            if len(datasets) != 0:\n",
    "                train_relationship = dict()\n",
    "                train_relationship[\"Models\"] = extract_name(model.id)\n",
    "                train_relationship[\"Datasets\"] = [extract_name(dataset) for dataset in datasets]\n",
    "                add_to_json_file(train_relationship, file_path)\n",
    "            count += 1\n",
    "            if count % 10000 == 0:\n",
    "                print(f'{count} models processed, {time.time() - start_time} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_train_relationship()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data as a DataFrame\n",
    "\n",
    "file_path = os.path.join(result_path, 'train_duplicates.json')\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "\tdata = json.load(file)\n",
    "train_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "\n",
    "print(f'len before removing duplicates: {len(train_df)}')\n",
    "train_df = train_df.loc[train_df.astype(str).drop_duplicates().index]\n",
    "print(f'len after removing duplicates: {len(train_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_postprocessed = os.path.join(result_path, 'train.json')\n",
    "\n",
    "with open(file_path_postprocessed, \"w\") as json_file:\n",
    "\tjson.dump(train_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuitedFor relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_suited_for_relationship():\n",
    "\n",
    "    file_path = os.path.join(result_path, 'suited_for_duplicates.json')\n",
    "\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    for task in TAG_DOWNSTREAM_TASK:\n",
    "        print(f'Processing {task} models...')\n",
    "        models = api.list_models(filter=task, full=True)\n",
    "        for model in models:\n",
    "            suited_for_relationship = dict()\n",
    "            suited_for_relationship['LargeLanguageModel'] = extract_name(model.id)\n",
    "            suited_for_relationship['DownstreamTask'] = task\n",
    "            add_to_json_file(suited_for_relationship, file_path)\n",
    "            count += 1\n",
    "            if count % 10000 == 0:\n",
    "                print(f'{count} models processed, {time.time() - start_time} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_suited_for_relationship()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data as a DataFrame\n",
    "\n",
    "file_path = os.path.join(result_path, 'suited_for_duplicates.json')\n",
    "with open(file_path, 'r') as file:\n",
    "\tdata = json.load(file)\n",
    "suited_for_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge duplicates\n",
    "\n",
    "print(f'len before removing duplicates: {len(suited_for_df)}')\n",
    "suited_for_df = suited_for_df.groupby('LargeLanguageModel')['DownstreamTask'].apply(list).reset_index()\n",
    "print(f'len after removing duplicates: {len(suited_for_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_postprocessed = os.path.join(result_path, 'suited_for.json')\n",
    "\n",
    "with open(file_path_postprocessed, \"w\") as json_file:\n",
    "\tjson.dump(suited_for_df.to_dict(orient='records'), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enable_relationship():\n",
    "\n",
    "\tfile_path = os.path.join(result_path, 'enable_duplicates.json')\n",
    "\n",
    "\tcount = 0\n",
    "\tstart_time = time.time()\n",
    "\tfor task in TAG_DOWNSTREAM_TASK:\n",
    "\t\tprint(f'Processing {task} datasets...')\n",
    "\t\tdatasets = api.list_datasets(filter=task, full=True)\n",
    "\t\tfor dataset in datasets:\n",
    "\t\t\tenable_relationship = dict()\n",
    "\t\t\tenable_relationship['Dataset'] = extract_name(dataset.id)\n",
    "\t\t\tenable_relationship['DownstreamTask'] = task\n",
    "\t\t\tadd_to_json_file(enable_relationship, file_path)\n",
    "\t\t\tcount += 1\n",
    "\t\t\tif count % 1000 == 0:\n",
    "\t\t\t\tprint(f'{count} datasets processed, {time.time() - start_time} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_enable_relationship()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data as a DataFrame\n",
    "\n",
    "file_path = os.path.join(result_path, 'enable_duplicates.json')\n",
    "with open(file_path, 'r') as file:\n",
    "\tdata = json.load(file)\n",
    "enable_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge duplicates\n",
    "\n",
    "print(f'len before removing duplicates: {len(enable_df)}')\n",
    "enable_df = enable_df.groupby('Dataset')['DownstreamTask'].apply(list).reset_index()\n",
    "print(f'len after removing duplicates: {len(enable_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_postprocessed = os.path.join(result_path, 'enable.json')\n",
    "\n",
    "with open(file_path_postprocessed, \"w\") as json_file:\n",
    "\tjson.dump(enable_df.to_dict(orient='records'), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_assess_relationship():\n",
    "\n",
    "    assess = []\n",
    "    for task in TAG_DOWNSTREAM_TASK:\n",
    "        assess_element = {'Metric': [], 'DownstreamTask': task}\n",
    "        print(f\"Processing task: {task}\")\n",
    "        url = f\"https://huggingface.co/tasks/{task}\"\n",
    "        # Fetch the webpage\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "            return\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Extract all the <dl> elements\n",
    "        dl_elements = soup.find_all('dl', class_='flex items-center rounded-lg border border-gray-100')\n",
    "\n",
    "        # Loop through each <dl> element\n",
    "        for dl in dl_elements:\n",
    "            # Extract the metric name from the <dt> tag inside the <summary>\n",
    "            metric_name = dl.find('dt').get_text(strip=True)\n",
    "\n",
    "            assess_element['Metric'].append(metric_name)\n",
    "\n",
    "        assess.append(assess_element)\n",
    "\n",
    "    return assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_asess_relationship_json():\n",
    "\n",
    "\tassess_relationship = extract_assess_relationship()\n",
    "\n",
    "\tfile_path = os.path.join(result_path, 'assess.json')\n",
    "\n",
    "\twith open(file_path, 'w', encoding='utf-8') as f:\n",
    "\t\tjson.dump(assess_relationship, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_asess_relationship_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check that this is correct (the output and the model cards on HF do not seem to be coherent?)\n",
    "# Model card template: https://github.com/huggingface/hub-docs/blob/main/modelcard.md?plain=1\n",
    "\n",
    "def create_evaluate_relationship():\n",
    "\n",
    "\tfile_path = os.path.join(result_path, 'evaluate_duplicates.json')\n",
    "\n",
    "\tcount = 0\n",
    "\tstart_time = time.time()\n",
    "\tfor task in TAG_DOWNSTREAM_TASK:\n",
    "\t\tprint(f'Processing {task} models...')\n",
    "\t\tmodels = api.list_models(filter=task, full=True, cardData=True)\n",
    "\t\tfor model in models:\n",
    "\t\t\tif model.card_data is not None:\n",
    "\t\t\t\tmodel_card_data = model.card_data.to_dict()\n",
    "\t\t\t\tif 'metrics' in model_card_data:\n",
    "\t\t\t\t\tmetrics = model_card_data['metrics']\n",
    "\t\t\t\t\tevaluate_relationship = dict()\n",
    "\t\t\t\t\tevaluate_relationship['LargeLanguageModel'] = extract_name(model.id)\n",
    "\t\t\t\t\tevaluate_relationship['Metric'] = metrics\n",
    "\t\t\t\t\tadd_to_json_file(evaluate_relationship, file_path)\n",
    "\t\t\tcount += 1\n",
    "\t\t\tif count % 10000 == 0:\n",
    "\t\t\t\tprint(f'{count} models processed, {time.time() - start_time} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_evaluate_relationship()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data as a DataFrame\n",
    "\n",
    "file_path = os.path.join(result_path, 'evaluate_duplicates.json')\n",
    "with open(file_path, 'r') as file:\n",
    "\tdata = json.load(file)\n",
    "evaluate_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "\n",
    "print(f'len before removing duplicates: {len(evaluate_df)}')\n",
    "evaluate_df = evaluate_df.loc[evaluate_df.astype(str).drop_duplicates().index]\n",
    "print(f'len after removing duplicates: {len(evaluate_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_list = evaluate_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_postprocessed = os.path.join(result_path, 'evaluate.json')\n",
    "\n",
    "with open(file_path_postprocessed, \"w\") as json_file:\n",
    "\tjson.dump(evaluate_list, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
