[
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5a8"
        },
        "name": "LLaMA",
        "version": 1,
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": null,
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 14,
        "tokenizer": "BPE model based on sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5a9"
        },
        "name": "LLaMA",
        "version": 1,
        "numberOfParameters [B]": 13,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": null,
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 23,
        "tokenizer": "BPE model based on sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5aa"
        },
        "name": "LLaMA",
        "version": 1,
        "numberOfParameters [B]": 33,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": null,
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 90,
        "tokenizer": "BPE model based on sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ab"
        },
        "name": "LLaMA",
        "version": 1,
        "numberOfParameters [B]": 65,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": null,
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 173,
        "tokenizer": "BPE model based on sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ac"
        },
        "name": "LLaMA",
        "version": 2,
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 31.22,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ad"
        },
        "name": "LLaMA",
        "version": 2,
        "numberOfParameters [B]": 13,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 62.44,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ae"
        },
        "name": "LLaMA",
        "version": 2,
        "numberOfParameters [B]": 34,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 153.9,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5af"
        },
        "name": "LLaMA",
        "version": 2,
        "numberOfParameters [B]": 70,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 291.42,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b0"
        },
        "name": "LLaMA",
        "version": 3,
        "numberOfParameters [B]": 8,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama3 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 8192,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 390,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b1"
        },
        "name": "LLaMA",
        "version": 3,
        "numberOfParameters [B]": 70,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama3 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 8192,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 1900,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b2"
        },
        "name": "LLaMA",
        "version": "3-instruct",
        "numberOfParameters [B]": 8,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama3 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 8192,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 1900,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b3"
        },
        "name": "LLaMA",
        "version": "3-instruct",
        "numberOfParameters [B]": 70,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama3 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 8192,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 1900,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b4"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 0.125,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b5"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 0.35,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b6"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 1.3,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b7"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 2.7,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b8"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 6.7,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5b9"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 13,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ba"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 30,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5bb"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 66,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5bc"
        },
        "name": "OPT",
        "version": null,
        "numberOfParameters [B]": 175,
        "quantization": null,
        "architecture": "OPT",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "opt license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 75,
        "tokenizer": "GPT-2 byte level BPE tokenizer"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5bd"
        },
        "name": "LLaMA",
        "version": "2-Chat",
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 31.22,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5be"
        },
        "name": "LLaMA",
        "version": "2-Chat",
        "numberOfParameters [B]": 13,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 62.44,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5bf"
        },
        "name": "LLaMA",
        "version": "2-Chat",
        "numberOfParameters [B]": 70,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "German",
            "English",
            "Spanish",
            "French",
            "Croatian",
            "Hungarian",
            "Italian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Ukrainian"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 291.42,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c0"
        },
        "name": "Code LLaMA",
        "version": null,
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c1"
        },
        "name": "Code LLaMA",
        "version": null,
        "numberOfParameters [B]": 13,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c2"
        },
        "name": "Code LLaMA",
        "version": null,
        "numberOfParameters [B]": 34,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c3"
        },
        "name": "Code LLaMA",
        "version": null,
        "numberOfParameters [B]": 70,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c4"
        },
        "name": "Code LLaMA",
        "version": "Python",
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c5"
        },
        "name": "Code LLaMA",
        "version": "Python",
        "numberOfParameters [B]": 13,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c6"
        },
        "name": "Code LLaMA",
        "version": "Python",
        "numberOfParameters [B]": 34,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c7"
        },
        "name": "Code LLaMA",
        "version": "Python",
        "numberOfParameters [B]": 70,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c8"
        },
        "name": "Code LLaMA",
        "version": "Instruct",
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5c9"
        },
        "name": "Code LLaMA",
        "version": "Instruct",
        "numberOfParameters [B]": 13,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ca"
        },
        "name": "Code LLaMA",
        "version": "Instruct",
        "numberOfParameters [B]": 34,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5cb"
        },
        "name": "Code LLaMA",
        "version": "Instruct",
        "numberOfParameters [B]": 70,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 100000,
        "developers": [
            "Meta"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 288.55,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5cc"
        },
        "name": "Galactica",
        "version": null,
        "numberOfParameters [B]": 0.125,
        "quantization": null,
        "architecture": "Galactica",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "CC BY-NC 4.0",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Custom"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5cd"
        },
        "name": "Galactica",
        "version": null,
        "numberOfParameters [B]": 1.3,
        "quantization": null,
        "architecture": "Galactica",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "CC BY-NC 4.0",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Custom"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ce"
        },
        "name": "Galactica",
        "version": null,
        "numberOfParameters [B]": 6.7,
        "quantization": null,
        "architecture": "Galactica",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "CC BY-NC 4.0",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Custom"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5cf"
        },
        "name": "Galactica",
        "version": null,
        "numberOfParameters [B]": 30,
        "quantization": null,
        "architecture": "Galactica",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "CC BY-NC 4.0",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Custom"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d0"
        },
        "name": "Galactica",
        "version": null,
        "numberOfParameters [B]": 120,
        "quantization": null,
        "architecture": "Galactica",
        "languages": [
            "English"
        ],
        "modelCreator": "Meta",
        "licenseToUse": "CC BY-NC 4.0",
        "libraryFramework": "PyTorch",
        "contextLength": 2048,
        "developers": [
            "Meta"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Custom"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d1"
        },
        "name": "BERT",
        "version": null,
        "numberOfParameters [B]": 0.34,
        "quantization": null,
        "architecture": "BERT",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "Tensor2Tensor",
        "contextLength": 512,
        "developers": [
            "Google"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "WordPiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d2"
        },
        "name": "T5",
        "version": null,
        "numberOfParameters [B]": 11,
        "quantization": null,
        "architecture": "T5",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "Mesh TensorFlow",
        "contextLength": 512,
        "developers": [
            "Google"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d3"
        },
        "name": "XLNet",
        "version": null,
        "numberOfParameters [B]": 0.34,
        "quantization": null,
        "architecture": "XLNet",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": null,
        "contextLength": 512,
        "developers": [
            "Google"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d4"
        },
        "name": "GLaM",
        "version": null,
        "numberOfParameters [B]": 1200,
        "quantization": null,
        "architecture": "GLaM",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "Proprietary",
        "libraryFramework": "Mesh TensorFlow",
        "contextLength": 1024,
        "developers": [
            "Google"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 40.2,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d5"
        },
        "name": "Gopher",
        "version": null,
        "numberOfParameters [B]": 280,
        "quantization": null,
        "architecture": "Gopher",
        "languages": [
            "English"
        ],
        "modelCreator": "DeepMind",
        "licenseToUse": "Proprietary",
        "libraryFramework": "JAX",
        "contextLength": 2048,
        "developers": [
            "DeepMind"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 380,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d6"
        },
        "name": "LaMDA",
        "version": null,
        "numberOfParameters [B]": 137,
        "quantization": null,
        "architecture": "LaMDA",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "Proprietary",
        "libraryFramework": "Lingvo (TensorFlow)",
        "contextLength": 1024,
        "developers": [
            "Google"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 25.2,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d7"
        },
        "name": "Chincilla",
        "version": null,
        "numberOfParameters [B]": 70,
        "quantization": null,
        "architecture": "Chincilla",
        "languages": [
            "English"
        ],
        "modelCreator": "DeepMind",
        "licenseToUse": "Proprietary",
        "libraryFramework": "JAX",
        "contextLength": 8192,
        "developers": [
            "DeepMind"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d8"
        },
        "name": "PaLM",
        "version": "1",
        "numberOfParameters [B]": 540,
        "quantization": null,
        "architecture": "PaLM",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "Proprietary",
        "libraryFramework": "JAX",
        "contextLength": 2048,
        "developers": [
            "Google"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 271.43,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5d9"
        },
        "name": "Minerva",
        "version": null,
        "numberOfParameters [B]": 540,
        "quantization": null,
        "architecture": "Minerva",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "Proprietary",
        "libraryFramework": "JAX",
        "contextLength": 2048,
        "developers": [
            "Google"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5da"
        },
        "name": "PaLM",
        "version": "2",
        "numberOfParameters [B]": 340,
        "quantization": null,
        "architecture": "PaLM",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "Proprietary",
        "libraryFramework": "JAX",
        "contextLength": 8000,
        "developers": [
            "Google"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5db"
        },
        "name": "Gemini",
        "version": "1.0 - Nano-1",
        "numberOfParameters [B]": 1.8,
        "quantization": "4-bit",
        "architecture": "Gemini",
        "languages": [
            "English",
            "Japanese",
            "Korean",
            "Arabic",
            "Bengali",
            "Bulgarian",
            "Czech",
            "Chinese (Simplified/Traditional)",
            "Croatian",
            "Danish",
            "Hebrew",
            "Estonian",
            "Farsi",
            "Finnish",
            "French",
            "Greek",
            "Gujarati",
            "Hindi",
            "Indonesian",
            "Italian",
            "Kannada",
            "Latvian",
            "Lithuanian",
            "Malayalam",
            "Marathi",
            "Norwegian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Serbian",
            "Slovak",
            "Slovenian",
            "Spanish",
            "Swedish",
            "Swahili",
            "Tamil",
            "German",
            "Telugu",
            "Thai",
            "Turkish",
            "Ukrainian",
            "Hungarian",
            "Urdu",
            "Vietnamese"
        ],
        "modelCreator": "Google DeepMind",
        "licenseToUse": "Proprietary",
        "libraryFramework": "JAX",
        "contextLength": 32000,
        "developers": [
            "Google DeepMind"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5dc"
        },
        "name": "Gemini",
        "version": "1.0 - Nano-2",
        "numberOfParameters [B]": 3.25,
        "quantization": null,
        "architecture": "Gemini",
        "languages": [
            "English",
            "Japanese",
            "Korean",
            "Arabic",
            "Bengali",
            "Bulgarian",
            "Czech",
            "Chinese (Simplified/Traditional)",
            "Croatian",
            "Danish",
            "Hebrew",
            "Estonian",
            "Farsi",
            "Finnish",
            "French",
            "Greek",
            "Gujarati",
            "Hindi",
            "Indonesian",
            "Italian",
            "Kannada",
            "Latvian",
            "Lithuanian",
            "Malayalam",
            "Marathi",
            "Norwegian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Serbian",
            "Slovak",
            "Slovenian",
            "Spanish",
            "Swedish",
            "Swahili",
            "Tamil",
            "German",
            "Telugu",
            "Thai",
            "Turkish",
            "Ukrainian",
            "Hungarian",
            "Urdu",
            "Vietnamese"
        ],
        "modelCreator": "Google DeepMind",
        "licenseToUse": "Proprietary",
        "libraryFramework": "JAX",
        "contextLength": 32000,
        "developers": [
            "Google DeepMind"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5dd"
        },
        "name": "Gemini",
        "version": "1.5",
        "numberOfParameters [B]": null,
        "quantization": null,
        "architecture": "Gemini",
        "languages": [
            "English",
            "Japanese",
            "Korean",
            "Arabic",
            "Bengali",
            "Bulgarian",
            "Czech",
            "Chinese (Simplified/Traditional)",
            "Croatian",
            "Danish",
            "Hebrew",
            "Estonian",
            "Farsi",
            "Finnish",
            "French",
            "Greek",
            "Gujarati",
            "Hindi",
            "Indonesian",
            "Italian",
            "Kannada",
            "Latvian",
            "Lithuanian",
            "Malayalam",
            "Marathi",
            "Norwegian",
            "Dutch",
            "Polish",
            "Portuguese",
            "Romanian",
            "Russian",
            "Serbian",
            "Slovak",
            "Slovenian",
            "Spanish",
            "Swedish",
            "Swahili",
            "Tamil",
            "German",
            "Telugu",
            "Thai",
            "Turkish",
            "Ukrainian",
            "Hungarian",
            "Urdu",
            "Vietnamese"
        ],
        "modelCreator": "Google DeepMind",
        "licenseToUse": "Proprietary",
        "libraryFramework": "JAX",
        "contextLength": 10000000,
        "developers": [
            "Google DeepMind"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5de"
        },
        "name": "Gemma",
        "version": null,
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "Gemma",
        "languages": [
            "English"
        ],
        "modelCreator": "Google DeepMind",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "JAX",
        "contextLength": 8192,
        "developers": [
            "Google DeepMind"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": 131,
        "tokenizer": "SentencePiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5df"
        },
        "name": "GPT-3",
        "version": "3.5",
        "numberOfParameters [B]": 175,
        "quantization": null,
        "architecture": "GPT-3",
        "languages": [
            "Multilingual"
        ],
        "modelCreator": "OpenAI",
        "licenseToUse": "Proprietary",
        "libraryFramework": null,
        "contextLength": 2048,
        "developers": [
            "OpenAI"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": "Estimated",
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e0"
        },
        "name": "ChatGPT",
        "version": "3.5+",
        "numberOfParameters [B]": 175,
        "quantization": null,
        "architecture": "ChatGPT",
        "languages": [
            "Multilingual"
        ],
        "modelCreator": "OpenAI",
        "licenseToUse": "Proprietary",
        "libraryFramework": null,
        "contextLength": 4096,
        "developers": [
            "OpenAI"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": "Estimated",
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e1"
        },
        "name": "GPT-2",
        "version": "1.5",
        "numberOfParameters [B]": 1.5,
        "quantization": null,
        "architecture": "GPT-2",
        "languages": [
            "English"
        ],
        "modelCreator": "OpenAI",
        "licenseToUse": "MIT",
        "libraryFramework": null,
        "contextLength": 1024,
        "developers": [
            "OpenAI"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": "Estimated",
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e2"
        },
        "name": "GPT-4",
        "version": "4.0",
        "numberOfParameters [B]": 1760,
        "quantization": null,
        "architecture": "GPT-4",
        "languages": [
            "Multilingual"
        ],
        "modelCreator": "OpenAI",
        "licenseToUse": "Proprietary",
        "libraryFramework": null,
        "contextLength": 8192,
        "developers": [
            "OpenAI"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": "Estimated",
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e3"
        },
        "name": "Mistral ",
        "version": "0.1",
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "Mistral ",
        "languages": [
            "English",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "PyTorch",
        "contextLength": 32000,
        "developers": [
            "MistralAI"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v1"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e4"
        },
        "name": "Mistral",
        "version": "0.1 - Instruct",
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "Mistral",
        "languages": [
            "English",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "PyTorch",
        "contextLength": 32000,
        "developers": [
            "MistralAI"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v1"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e5"
        },
        "name": "Mistral",
        "version": "0.2 - Instruct",
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "Mistral",
        "languages": [
            "English",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "PyTorch",
        "contextLength": 32000,
        "developers": [
            "MistralAI"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v1"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e6"
        },
        "name": "Mixtral 8x7B",
        "version": "0.1",
        "numberOfParameters [B]": 46.7,
        "quantization": null,
        "architecture": "Mixtral",
        "languages": [
            "English",
            "Spanish",
            "Italian",
            "French",
            "German",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "PyTorch",
        "contextLength": 32000,
        "developers": [
            "MistralAI"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v1"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e7"
        },
        "name": "Mixtral 8x7B",
        "version": "0.1 - Instruct",
        "numberOfParameters [B]": 46.7,
        "quantization": null,
        "architecture": "Mixtral",
        "languages": [
            "English",
            "Spanish",
            "Italian",
            "French",
            "German",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "PyTorch",
        "contextLength": 32000,
        "developers": [
            "MistralAI"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v1"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e8"
        },
        "name": "Mixtral 8x22B",
        "version": "0.1 ",
        "numberOfParameters [B]": 141,
        "quantization": null,
        "architecture": "Mixtral",
        "languages": [
            "English",
            "Spanish",
            "Italian",
            "French",
            "German",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "PyTorch",
        "contextLength": 64000,
        "developers": [
            "MistralAI"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v3"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5e9"
        },
        "name": "Mixtral 8x22B",
        "version": "0.1 - Instruct",
        "numberOfParameters [B]": 141,
        "quantization": null,
        "architecture": "Mixtral",
        "languages": [
            "English",
            "Spanish",
            "Italian",
            "French",
            "German",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": "PyTorch",
        "contextLength": 64000,
        "developers": [
            "MistralAI"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v3"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ea"
        },
        "name": "Mixtral Large",
        "version": null,
        "numberOfParameters [B]": null,
        "quantization": null,
        "architecture": "Mixtral",
        "languages": [
            "English",
            "Spanish",
            "Italian",
            "French",
            "German",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Proprietary",
        "libraryFramework": null,
        "contextLength": 32000,
        "developers": [
            "MistralAI"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v2"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5eb"
        },
        "name": "Mistral Small",
        "version": null,
        "numberOfParameters [B]": null,
        "quantization": null,
        "architecture": "Mistral",
        "languages": [
            "English",
            "Spanish",
            "Italian",
            "French",
            "German",
            "Code"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Proprietary",
        "libraryFramework": null,
        "contextLength": 32000,
        "developers": [
            "MistralAI"
        ],
        "openSource": false,
        "uri": null,
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "Byte-fallback BPE - Mistral tokenizer v2"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ec"
        },
        "name": "roberta-base-openai-detector",
        "version": null,
        "numberOfParameters [B]": 0.125,
        "quantization": null,
        "architecture": "RoBERTa",
        "languages": [
            "English"
        ],
        "modelCreator": "Google",
        "licenseToUse": "MIT",
        "libraryFramework": "[PyTorch, TensorFlow]",
        "contextLength": 150,
        "developers": [
            "OpenAI-community"
        ],
        "openSource": true,
        "uri": "https://huggingface.co/openai-community/roberta-base-openai-detector",
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "BPE"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ed"
        },
        "name": "Mistral-Finetuned-DialogSumm",
        "version": null,
        "numberOfParameters [B]": 1.2,
        "quantization": null,
        "architecture": "Mistral",
        "languages": [
            "English"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "Apache-2.0",
        "libraryFramework": null,
        "contextLength": 32768,
        "developers": [
            "Villian7"
        ],
        "openSource": true,
        "uri": "https://huggingface.co/Villian7/Mistral-Finetuned-DialogSumm",
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": null
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ee"
        },
        "name": "RM-Mistral-7B",
        "version": null,
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "Mistral",
        "languages": [
            "Multilingual"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": null,
        "libraryFramework": null,
        "contextLength": 32768,
        "developers": [
            "weqweasdas"
        ],
        "openSource": true,
        "uri": "https://huggingface.co/weqweasdas/RM-Mistral-7B",
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": null
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5ef"
        },
        "name": "SaulLM7B",
        "version": null,
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "Mistral",
        "languages": [
            "English"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "MIT",
        "libraryFramework": "PyTorch",
        "contextLength": 3200,
        "developers": [
            "Equall.ai"
        ],
        "openSource": true,
        "uri": "nulll",
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": null
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5f0"
        },
        "name": "SaulLM7B",
        "version": "Instruct",
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "Mistral",
        "languages": [
            "English"
        ],
        "modelCreator": "MistralAI",
        "licenseToUse": "MIT",
        "libraryFramework": "PyTorch",
        "contextLength": 3200,
        "developers": [
            "Equall.ai"
        ],
        "openSource": true,
        "uri": null,
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": null
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5f1"
        },
        "name": "StarCoder",
        "version": null,
        "numberOfParameters [B]": 15,
        "quantization": null,
        "architecture": "Transformer",
        "languages": [
            "Multilingual",
            "Code"
        ],
        "modelCreator": "BigCode",
        "licenseToUse": "OpenRail",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "BigCode"
        ],
        "openSource": true,
        "uri": "https://huggingface.co/bigcode/starcoder2-15b",
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5f2"
        },
        "name": "StarCoder",
        "version": null,
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "Transformer",
        "languages": [
            "Multilingual",
            "Code"
        ],
        "modelCreator": "BigCode",
        "licenseToUse": "OpenRail",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "BigCode"
        ],
        "openSource": true,
        "uri": "https://huggingface.co/bigcode/starcoder2-7b",
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5f3"
        },
        "name": "StarCoder",
        "version": null,
        "numberOfParameters [B]": 3,
        "quantization": null,
        "architecture": "Transformer",
        "languages": [
            "Multilingual",
            "Code"
        ],
        "modelCreator": "BigCode",
        "licenseToUse": "OpenRail",
        "libraryFramework": "PyTorch",
        "contextLength": 4096,
        "developers": [
            "BigCode"
        ],
        "openSource": true,
        "uri": "https://huggingface.co/bigcode/starcoder2-3b",
        "fineTuned": false,
        "carbonEmission [CO2eq tons]": null,
        "tokenizer": "BPE model based in sentencepiece"
    },
    {
        "_id": {
            "$oid": "66ab8559444e3f9fec2ec5f4"
        },
        "name": "MEDITRON",
        "version": null,
        "numberOfParameters [B]": 7,
        "quantization": null,
        "architecture": "LLaMA",
        "languages": [
            "English"
        ],
        "modelCreator": "EPFL",
        "licenseToUse": "llama2 community license agreement",
        "libraryFramework": "PyTorch",
        "contextLength": 2000,
        "developers": [
            "EPFL"
        ],
        "openSource": true,
        "uri": "https://arxiv.org/pdf/2311.16079",
        "fineTuned": true,
        "carbonEmission [CO2eq tons]": 0.0068,
        "tokenizer": "BPE model based in sentencepiece"
    }
]